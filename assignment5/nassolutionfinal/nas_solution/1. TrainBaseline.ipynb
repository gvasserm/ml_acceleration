{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1174cb",
   "metadata": {},
   "source": [
    "# Single Path One-Shot Neural Architecture Search using Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368eef94",
   "metadata": {},
   "source": [
    "### Make everything a bit faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63906da",
   "metadata": {},
   "source": [
    "Your task is to implement SPOS + Random Search to find the optimal ResNet-18-like architecture\n",
    "for image classification on CIFAR-10 dataset.\n",
    "\n",
    "### Proposed search space\n",
    "The same search space as in the lecture, but without kernel size search.\n",
    "This means that each search block should only have 3 operations.\n",
    "\n",
    "### Latency awareness\n",
    "While searching, you should implement hard constraint on model latency. As a proxy for\n",
    "latency, use the number of MACs. The baseline ResNet-18 has 37M MACs for images of size 32x32.\n",
    "The final selected architecture should have at most 30M MACs.\n",
    "You can find an example computation for the number of MACs in this notebook.\n",
    "\n",
    "### How to complete the task\n",
    "Plan for your experiments:\n",
    "1. Train baseline ResNet-18 model.  **(2 pts)**\n",
    "2. Finalize supernet code. **(15 pts)**\n",
    "3. Train supernet with the same hyperparameters except the number of epochs. You should increase\n",
    "   it by a factor of 3-6. Save supernet weights.  **(10 pts)**\n",
    "4. Write implementation for Random Search.  **(10 pts)**\n",
    "5. Run it for 100-1000 iterations by measuring accuracies of models from the supernet.\n",
    "   Keep track of each model accuracy and latency.  **(5 pts)**\n",
    "6. Train the best architecture from scratch. For this, you can build the whole supernet, and\n",
    "   select this architecture for all the forward passes of the training.  **(6 pts)**\n",
    "7. Compare with the model from step 1. Does your model have a better accuracy?  **(2 pts)**\n",
    "\n",
    "### Code structure\n",
    "\n",
    "Main.ipynb - Learn your neural networks here.\n",
    "\n",
    "resnet.py - ResNet-18 implementation from torchvision, simplified for this project.\n",
    "\n",
    "supernet.py - Unfinished Supernet implementation.\n",
    "\n",
    "cifar10.py - Transforms for CIFAR-10 training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977c856",
   "metadata": {},
   "source": [
    "# Train baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b67ad",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f0fd3f",
   "metadata": {},
   "source": [
    "Before you begin, make sure to install torch, torchvision, numpy, thop and tqdm libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b276c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision numpy thop tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e2d25",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ba7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from thop import profile\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cifar10 import get_train_transform, get_val_transform\n",
    "from resnet import resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9e40b",
   "metadata": {},
   "source": [
    "### Make everything a bit faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32970714",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429fa228",
   "metadata": {},
   "source": [
    "### Build datasets and dataloaders for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92e57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this value if needed.\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aed8f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = get_train_transform()\n",
    "val_transform = get_val_transform()\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform,\n",
    ")\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a2e7e",
   "metadata": {},
   "source": [
    "## Create your baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7769c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select suitable device.\n",
    "# You should probably use either cuda (NVidia GPU) or mps (Apple) backend.\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "404e7019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(num_classes=10, zero_init_residual=True)\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e78f87",
   "metadata": {},
   "source": [
    "### Compute the number of MACs and parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5abcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'resnet.BasicBlock'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'resnet.ResNet'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "Number of macs: 37.12M, number of parameters: 11.18M\n"
     ]
    }
   ],
   "source": [
    "macs, params = profile(model, inputs=(torch.zeros(1, 3, 32, 32, device=device),))\n",
    "print(f'Number of macs: {macs / 1e6:.2f}M, number of parameters: {params / 1e6:.2f}M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b63ff",
   "metadata": {},
   "source": [
    "## Train baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d28bd",
   "metadata": {},
   "source": [
    "### Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adb69e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a17ef6",
   "metadata": {},
   "source": [
    "### Select hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c73bcfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.25\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.9\n",
    "n_epochs = 20  # Longer training gives better results, but let's keep baseline model epochs to 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a88db",
   "metadata": {},
   "source": [
    "### Build optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "701d2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_dataloader) * n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01dec24",
   "metadata": {},
   "source": [
    "### Define training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc6e0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in wrapped_dataloader:\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (predicted_labels == labels).sum().item()\n",
    "            total_samples += labels.shape[0]\n",
    "\n",
    "        wrapped_dataloader.set_description(\n",
    "            f'(train) Epoch={epoch}, lr={scheduler.get_last_lr()[0]:.4f} loss={total_loss / (i + 1):.3f}'\n",
    "        )\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in wrapped_dataloader:\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (predicted_labels == labels).sum().item()\n",
    "        total_samples += labels.shape[0]\n",
    "\n",
    "        wrapped_dataloader.set_description(f'(val) Epoch={epoch}, loss={total_loss / (i + 1):.3f}')\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c3ea7d",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682721bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=0, lr=0.2485 loss=1.988: 100%|███████████████████████████████████████████| 97/97 [00:20<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.9877, train_accuracy=28.278%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=0, loss=1.488: 100%|███████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.4876, test_accuracy=44.240%\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=1, lr=0.2439 loss=1.417: 100%|███████████████████████████████████████████| 97/97 [00:05<00:00, 18.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4168, train_accuracy=48.097%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=1, loss=1.298: 100%|███████████████████████████████████████████████████████| 20/20 [00:00<00:00, 21.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.2984, test_accuracy=53.960%\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=2, lr=0.2364 loss=1.212: 100%|███████████████████████████████████████████| 97/97 [00:05<00:00, 18.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.2118, train_accuracy=56.457%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=2, loss=1.175: 100%|███████████████████████████████████████████████████████| 20/20 [00:00<00:00, 22.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.1750, test_accuracy=58.540%\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=3, lr=0.2261 loss=1.070: 100%|███████████████████████████████████████████| 97/97 [00:05<00:00, 18.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.0698, train_accuracy=61.789%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=3, loss=0.975: 100%|███████████████████████████████████████████████████████| 20/20 [00:00<00:00, 22.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.9755, test_accuracy=65.870%\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=4, lr=0.2134 loss=0.984: 100%|███████████████████████████████████████████| 97/97 [00:05<00:00, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.9839, train_accuracy=65.041%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=4, loss=0.949: 100%|███████████████████████████████████████████████████████| 20/20 [00:00<00:00, 22.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.9490, test_accuracy=66.460%\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=5, lr=0.1985 loss=0.915: 100%|███████████████████████████████████████████| 97/97 [00:05<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.9146, train_accuracy=67.516%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=5, loss=0.913: 100%|███████████████████████████████████████████████████████| 20/20 [00:00<00:00, 21.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.9129, test_accuracy=67.890%\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=6, lr=0.1817 loss=0.870: 100%|███████████████████████████████████████████| 97/97 [00:05<00:00, 18.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.8703, train_accuracy=69.149%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=6, loss=0.831: 100%|███████████████████████████████████████████████████████| 20/20 [00:00<00:00, 21.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.8313, test_accuracy=70.970%\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=7, lr=0.1636 loss=0.811: 100%|███████████████████████████████████████████| 97/97 [00:05<00:00, 18.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.8113, train_accuracy=71.378%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=7, loss=0.810: 100%|███████████████████████████████████████████████████████| 20/20 [00:00<00:00, 21.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.8100, test_accuracy=72.130%\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=8, lr=0.1446 loss=0.763: 100%|███████████████████████████████████████████| 97/97 [00:05<00:00, 18.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.7630, train_accuracy=73.192%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=8, loss=0.788: 100%|███████████████████████████████████████████████████████| 20/20 [00:00<00:00, 23.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7882, test_accuracy=72.540%\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=9, lr=0.1250 loss=0.715: 100%|███████████████████████████████████████████| 97/97 [00:05<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.7150, train_accuracy=74.893%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=9, loss=0.838: 100%|███████████████████████████████████████████████████████| 20/20 [00:00<00:00, 21.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.8379, test_accuracy=71.900%\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=10, lr=0.1054 loss=0.676: 100%|██████████████████████████████████████████| 97/97 [00:05<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6756, train_accuracy=76.281%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=10, loss=0.724: 100%|██████████████████████████████████████████████████████| 20/20 [00:00<00:00, 22.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7239, test_accuracy=74.820%\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=11, lr=0.0864 loss=0.635: 100%|██████████████████████████████████████████| 97/97 [00:05<00:00, 17.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6347, train_accuracy=77.724%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=11, loss=0.716: 100%|██████████████████████████████████████████████████████| 20/20 [00:00<00:00, 23.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7158, test_accuracy=75.640%\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=12, lr=0.0683 loss=0.601: 100%|██████████████████████████████████████████| 97/97 [00:05<00:00, 18.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6009, train_accuracy=78.864%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=12, loss=0.632: 100%|██████████████████████████████████████████████████████| 20/20 [00:00<00:00, 21.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.6317, test_accuracy=78.620%\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=13, lr=0.0515 loss=0.556: 100%|██████████████████████████████████████████| 97/97 [00:05<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.5560, train_accuracy=80.640%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=13, loss=0.586: 100%|██████████████████████████████████████████████████████| 20/20 [00:00<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5860, test_accuracy=79.600%\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=14, lr=0.0366 loss=0.515: 100%|██████████████████████████████████████████| 97/97 [00:05<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.5153, train_accuracy=81.769%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=14, loss=0.558: 100%|██████████████████████████████████████████████████████| 20/20 [00:00<00:00, 23.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5579, test_accuracy=80.790%\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=15, lr=0.0239 loss=0.481: 100%|██████████████████████████████████████████| 97/97 [00:05<00:00, 18.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4814, train_accuracy=83.161%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=15, loss=0.557: 100%|██████████████████████████████████████████████████████| 20/20 [00:00<00:00, 20.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5575, test_accuracy=81.230%\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=16, lr=0.0136 loss=0.446: 100%|██████████████████████████████████████████| 97/97 [00:05<00:00, 18.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4462, train_accuracy=84.456%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=16, loss=0.518: 100%|██████████████████████████████████████████████████████| 20/20 [00:00<00:00, 23.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5184, test_accuracy=82.500%\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=17, lr=0.0061 loss=0.420: 100%|██████████████████████████████████████████| 97/97 [00:05<00:00, 18.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4203, train_accuracy=85.404%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=17, loss=0.508: 100%|██████████████████████████████████████████████████████| 20/20 [00:00<00:00, 22.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5080, test_accuracy=82.860%\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=18, lr=0.0015 loss=0.407: 100%|██████████████████████████████████████████| 97/97 [00:05<00:00, 18.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4070, train_accuracy=85.933%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=18, loss=0.501: 100%|██████████████████████████████████████████████████████| 20/20 [00:00<00:00, 22.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5006, test_accuracy=83.180%\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=19, lr=0.0000 loss=0.394: 100%|██████████████████████████████████████████| 97/97 [00:05<00:00, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.3936, train_accuracy=86.227%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=19, loss=0.499: 100%|██████████████████████████████████████████████████████| 20/20 [00:00<00:00, 22.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.4991, test_accuracy=83.100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    loss, accuracy = train_one_epoch(model, criterion, train_dataloader, optimizer, scheduler, device, epoch)\n",
    "    print(f'train_loss={loss:.4f}, train_accuracy={accuracy:.3%}')\n",
    "    loss, accuracy = validate_one_epoch(model, criterion, test_dataloader, device, epoch)\n",
    "    print(f'test_loss={loss:.4f}, test_accuracy={accuracy:.3%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c95733e",
   "metadata": {},
   "source": [
    "### Save trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a77290d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'baseline_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15fa78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
