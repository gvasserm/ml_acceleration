{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1174cb",
   "metadata": {},
   "source": [
    "# Single Path One-Shot Neural Architecture Search using Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368eef94",
   "metadata": {},
   "source": [
    "### Make everything a bit faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63906da",
   "metadata": {},
   "source": [
    "Your task is to implement SPOS + Random Search to find the optimal ResNet-18-like architecture\n",
    "for image classification on CIFAR-10 dataset.\n",
    "\n",
    "### Proposed search space\n",
    "The same search space as in the lecture, but without kernel size search.\n",
    "This means that each search block should only have 3 operations.\n",
    "\n",
    "### Latency awareness\n",
    "While searching, you should implement hard constraint on model latency. As a proxy for\n",
    "latency, use the number of MACs. The baseline ResNet-18 has 37M MACs for images of size 32x32.\n",
    "The final selected architecture should have at most 30M MACs.\n",
    "You can find an example computation for the number of MACs in this notebook.\n",
    "\n",
    "### How to complete the task\n",
    "Plan for your experiments:\n",
    "1. Train baseline ResNet-18 model.  **(2 pts)**\n",
    "2. Finalize supernet code. **(15 pts)**\n",
    "3. Train supernet with the same hyperparameters except the number of epochs. You should increase\n",
    "   it by a factor of 3-6. Save supernet weights.  **(10 pts)**\n",
    "4. Write implementation for Random Search.  **(10 pts)**\n",
    "5. Run it for 100-1000 iterations by measuring accuracies of models from the supernet.\n",
    "   Keep track of each model accuracy and latency.  **(5 pts)**\n",
    "6. Train the best architecture from scratch. For this, you can build the whole supernet, and\n",
    "   select this architecture for all the forward passes of the training.  **(6 pts)**\n",
    "7. Compare with the model from step 1. Does your model have a better accuracy?  **(2 pts)**\n",
    "\n",
    "### Code structure\n",
    "\n",
    "Main.ipynb - Learn your neural networks here.\n",
    "\n",
    "resnet.py - ResNet-18 implementation from torchvision, simplified for this project.\n",
    "\n",
    "supernet.py - Unfinished Supernet implementation.\n",
    "\n",
    "cifar10.py - Transforms for CIFAR-10 training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b67ad",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f0fd3f",
   "metadata": {},
   "source": [
    "Before you begin, make sure to install torch, torchvision, numpy, thop and tqdm libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b276c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/gvasserm/.local/lib/python3.10/site-packages (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision in /home/gvasserm/.local/lib/python3.10/site-packages (0.17.1+cu121)\n",
      "Requirement already satisfied: numpy in /home/gvasserm/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Collecting thop\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: tqdm in /home/gvasserm/.local/lib/python3.10/site-packages (4.66.2)\n",
      "Requirement already satisfied: filelock in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/gvasserm/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/gvasserm/.local/lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gvasserm/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/gvasserm/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: thop\n",
      "Successfully installed thop-0.1.1.post2209072238\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision numpy thop tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e2d25",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4ba7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from thop import profile\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cifar10 import get_train_transform, get_val_transform\n",
    "from resnet import resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9e40b",
   "metadata": {},
   "source": [
    "### Make everything a bit faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32970714",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429fa228",
   "metadata": {},
   "source": [
    "### Build datasets and dataloaders for CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b92e57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this value if needed.\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0aed8f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = get_train_transform()\n",
    "val_transform = get_val_transform()\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform,\n",
    ")\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a2e7e",
   "metadata": {},
   "source": [
    "## Create your baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7769c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select suitable device.\n",
    "# You should probably use either cuda (NVidia GPU) or mps (Apple) backend.\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "404e7019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(num_classes=10, zero_init_residual=True)\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e78f87",
   "metadata": {},
   "source": [
    "### Compute the number of MACs and parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5abcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "Number of macs: 37.22M, number of parameters: 11.18M\n"
     ]
    }
   ],
   "source": [
    "macs, params = profile(model, inputs=(torch.zeros(1, 3, 32, 32, device=device),))\n",
    "print(f'Number of macs: {macs / 1e6:.2f}M, number of parameters: {params / 1e6:.2f}M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b63ff",
   "metadata": {},
   "source": [
    "## Train baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d28bd",
   "metadata": {},
   "source": [
    "### Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adb69e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a17ef6",
   "metadata": {},
   "source": [
    "### Select hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c73bcfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.25\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.9\n",
    "n_epochs = 20  # Longer training gives better results, but let's keep baseline model epochs to 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a88db",
   "metadata": {},
   "source": [
    "### Build optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "701d2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_dataloader) * n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01dec24",
   "metadata": {},
   "source": [
    "### Define training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc6e0b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in wrapped_dataloader:\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (predicted_labels == labels).sum().item()\n",
    "            total_samples += labels.shape[0]\n",
    "\n",
    "        wrapped_dataloader.set_description(\n",
    "            f'(train) Epoch={epoch}, lr={scheduler.get_last_lr()[0]:.4f} loss={total_loss / (i + 1):.3f}'\n",
    "        )\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in wrapped_dataloader:\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (predicted_labels == labels).sum().item()\n",
    "        total_samples += labels.shape[0]\n",
    "\n",
    "        wrapped_dataloader.set_description(f'(val) Epoch={epoch}, loss={total_loss / (i + 1):.3f}')\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c3ea7d",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "682721bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=0, lr=0.2485 loss=2.084: 100%|██████████| 97/97 [00:03<00:00, 31.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.0840, train_accuracy=27.136%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(val) Epoch=0, loss=1.501: 100%|██████████| 20/20 [00:00<00:00, 49.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.5008, test_accuracy=45.030%\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=1, lr=0.2439 loss=1.463: 100%|██████████| 97/97 [00:02<00:00, 41.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4630, train_accuracy=46.643%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=1, loss=1.383: 100%|██████████| 20/20 [00:00<00:00, 72.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.3829, test_accuracy=51.530%\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=2, lr=0.2364 loss=1.263: 100%|██████████| 97/97 [00:02<00:00, 39.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.2633, train_accuracy=54.492%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=2, loss=1.212: 100%|██████████| 20/20 [00:00<00:00, 67.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.2115, test_accuracy=57.280%\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=3, lr=0.2261 loss=1.120: 100%|██████████| 97/97 [00:02<00:00, 40.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.1204, train_accuracy=59.957%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=3, loss=1.061: 100%|██████████| 20/20 [00:00<00:00, 70.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.0613, test_accuracy=62.770%\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=4, lr=0.2134 loss=1.022: 100%|██████████| 97/97 [00:02<00:00, 39.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.0218, train_accuracy=63.678%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=4, loss=0.950: 100%|██████████| 20/20 [00:00<00:00, 57.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.9496, test_accuracy=67.120%\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=5, lr=0.1985 loss=0.932: 100%|██████████| 97/97 [00:02<00:00, 40.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.9315, train_accuracy=67.113%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=5, loss=0.993: 100%|██████████| 20/20 [00:00<00:00, 69.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.9927, test_accuracy=65.250%\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=6, lr=0.1817 loss=0.881: 100%|██████████| 97/97 [00:02<00:00, 39.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.8812, train_accuracy=68.810%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=6, loss=0.938: 100%|██████████| 20/20 [00:00<00:00, 65.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.9383, test_accuracy=68.050%\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=7, lr=0.1636 loss=0.830: 100%|██████████| 97/97 [00:02<00:00, 39.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.8297, train_accuracy=70.995%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=7, loss=0.873: 100%|██████████| 20/20 [00:00<00:00, 56.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.8731, test_accuracy=70.450%\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=8, lr=0.1446 loss=0.774: 100%|██████████| 97/97 [00:02<00:00, 40.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.7739, train_accuracy=72.835%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=8, loss=0.818: 100%|██████████| 20/20 [00:00<00:00, 65.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.8178, test_accuracy=71.430%\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=9, lr=0.1250 loss=0.727: 100%|██████████| 97/97 [00:02<00:00, 39.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.7268, train_accuracy=74.366%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=9, loss=0.756: 100%|██████████| 20/20 [00:00<00:00, 65.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7563, test_accuracy=74.450%\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=10, lr=0.1054 loss=0.684: 100%|██████████| 97/97 [00:02<00:00, 40.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6837, train_accuracy=75.989%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=10, loss=0.777: 100%|██████████| 20/20 [00:00<00:00, 55.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7775, test_accuracy=73.340%\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=11, lr=0.0864 loss=0.645: 100%|██████████| 97/97 [00:02<00:00, 40.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6445, train_accuracy=77.616%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=11, loss=0.719: 100%|██████████| 20/20 [00:00<00:00, 72.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7192, test_accuracy=75.770%\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=12, lr=0.0683 loss=0.611: 100%|██████████| 97/97 [00:02<00:00, 39.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6110, train_accuracy=78.679%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=12, loss=0.617: 100%|██████████| 20/20 [00:00<00:00, 68.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.6170, test_accuracy=78.700%\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=13, lr=0.0515 loss=0.568: 100%|██████████| 97/97 [00:02<00:00, 40.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.5677, train_accuracy=80.265%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=13, loss=0.585: 100%|██████████| 20/20 [00:00<00:00, 67.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5854, test_accuracy=79.520%\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=14, lr=0.0366 loss=0.524: 100%|██████████| 97/97 [00:02<00:00, 39.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.5238, train_accuracy=81.826%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=14, loss=0.587: 100%|██████████| 20/20 [00:00<00:00, 68.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5869, test_accuracy=80.010%\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=15, lr=0.0239 loss=0.491: 100%|██████████| 97/97 [00:02<00:00, 39.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4909, train_accuracy=82.794%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=15, loss=0.536: 100%|██████████| 20/20 [00:00<00:00, 70.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5358, test_accuracy=81.770%\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=16, lr=0.0136 loss=0.454: 100%|██████████| 97/97 [00:02<00:00, 39.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4540, train_accuracy=84.170%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=16, loss=0.515: 100%|██████████| 20/20 [00:00<00:00, 64.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5154, test_accuracy=82.290%\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=17, lr=0.0061 loss=0.432: 100%|██████████| 97/97 [00:02<00:00, 40.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4317, train_accuracy=84.951%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=17, loss=0.506: 100%|██████████| 20/20 [00:00<00:00, 64.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5061, test_accuracy=82.580%\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=18, lr=0.0015 loss=0.410: 100%|██████████| 97/97 [00:02<00:00, 38.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4105, train_accuracy=85.708%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=18, loss=0.501: 100%|██████████| 20/20 [00:00<00:00, 63.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5009, test_accuracy=83.030%\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=19, lr=0.0000 loss=0.403: 100%|██████████| 97/97 [00:02<00:00, 35.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4032, train_accuracy=86.032%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=19, loss=0.501: 100%|██████████| 20/20 [00:00<00:00, 63.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5006, test_accuracy=83.060%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    loss, accuracy = train_one_epoch(model, criterion, train_dataloader, optimizer, scheduler, device, epoch)\n",
    "    print(f'train_loss={loss:.4f}, train_accuracy={accuracy:.3%}')\n",
    "    loss, accuracy = validate_one_epoch(model, criterion, test_dataloader, device, epoch)\n",
    "    print(f'test_loss={loss:.4f}, test_accuracy={accuracy:.3%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c95733e",
   "metadata": {},
   "source": [
    "### Save trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a77290d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'baseline_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1262a062",
   "metadata": {},
   "source": [
    "## Neural Architecture Search - Supernet training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8f5574",
   "metadata": {},
   "source": [
    "### Create supernet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acbc51a",
   "metadata": {},
   "source": [
    "**Before running code in this section, you need to finish supernet implementation.**\n",
    "\n",
    "Please, go to `supernet.py` file and inspect the current implementation of SearchBlock and Supernet classes.\n",
    "Pay attention to the TODOs. You need to implement all of them.\n",
    "\n",
    "Supernet and BasicBlock classes are modified versions of ResNet and BasicBlock classes from `resnet.py`.\n",
    "\n",
    "    Tip: to understand how the Supernet is constructed, compare the implementation of Supernet and ResNet classes. You should probably use diff tool in your IDE or something."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5213c9dd",
   "metadata": {},
   "source": [
    "Task: briefly describe the differences made to construct supernet.\n",
    "\n",
    "Differences:\n",
    "1. Bottleneck block is replaced by SearchBlock\n",
    "2. Supernet is designed for search the optimal SearchBlock structure per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae6f71f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supernet import supernet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30066746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define inner channel multipliers as in lecture.\n",
    "channel_multipliers = (0.5, 0.75, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f11a2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Supernet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SearchBlock(\n",
       "      (ops): ModuleList(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supernet = supernet18(num_classes=10, zero_init_residual=True, channel_multipliers=channel_multipliers)\n",
    "supernet.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c42bba",
   "metadata": {},
   "source": [
    "### Select hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b72ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define hyperparameters for supernet training.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.25\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.9\n",
    "n_epochs = 100  # Longer training gives better results, but let's keep baseline model epochs to 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f3ec3",
   "metadata": {},
   "source": [
    "### Build optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b2eda34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: build optimizer and scheduler for supernet training.\n",
    "optimizer = optim.SGD(supernet.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_dataloader) * n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b283fb",
   "metadata": {},
   "source": [
    "### Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04ec0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy `train_one_epoch` function here, rename to `pretrain_one_epoch`.\n",
    "#       Call `model.sample_random_architecture()` before making forward pass on each batch.\n",
    "def pretrain_one_epoch(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    #wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.sample_random_architecture()\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (predicted_labels == labels).sum().item()\n",
    "            total_samples += labels.shape[0]\n",
    "\n",
    "        # wrapped_dataloader.set_description(\n",
    "        #     f'(train) Epoch={epoch}, lr={scheduler.get_last_lr()[0]:.4f} loss={total_loss / (i + 1):.3f}'\n",
    "        # )\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    #wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (predicted_labels == labels).sum().item()\n",
    "        total_samples += labels.shape[0]\n",
    "\n",
    "        #wrapped_dataloader.set_description(f'(val) Epoch={epoch}, loss={total_loss / (i + 1):.3f}')\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca3c0ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "train_loss=4.2950, train_accuracy=10.710%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:02<04:09,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=5.3872, test_accuracy=8.600%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:49<03:14,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20\n",
      "train_loss=1.1102, train_accuracy=60.170%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:51<03:11,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.0415, test_accuracy=63.610%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [01:41<02:48,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40\n",
      "train_loss=0.7978, train_accuracy=72.237%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [01:44<02:48,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.9477, test_accuracy=68.290%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [02:42<02:06,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60\n",
      "train_loss=0.6222, train_accuracy=78.487%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [02:45<02:04,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7021, test_accuracy=76.230%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [03:46<01:05,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80\n",
      "train_loss=0.4646, train_accuracy=83.743%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [03:50<01:03,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5290, test_accuracy=82.080%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:52<00:00,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "    loss, accuracy = pretrain_one_epoch(supernet, criterion, train_dataloader, optimizer, scheduler, device, epoch)\n",
    "    if epoch % 20 ==0:\n",
    "        print(f'Epoch: {epoch}')\n",
    "        print(f'train_loss={loss:.4f}, train_accuracy={accuracy:.3%}')\n",
    "    loss, accuracy = validate_one_epoch(supernet, criterion, test_dataloader, device, epoch)\n",
    "    if epoch % 20 ==0:\n",
    "        print(f'test_loss={loss:.4f}, test_accuracy={accuracy:.3%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6b6b5",
   "metadata": {},
   "source": [
    "### Save supernet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4fdcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(supernet.state_dict(), 'supernet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b1489c",
   "metadata": {},
   "source": [
    "## Neural Architecture Search - Random Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4111c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure_latency(model: torch.nn.Module, device: torch.device, input_shape=(1, 3, 224, 224), dtype=torch.float32, warmup_iters=10, measure_iters=100) -> float:\n",
    "    \"\"\"\n",
    "    Measure the latency of a forward pass in a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "    - model: The PyTorch model to measure.\n",
    "    - device: The device to run the measurement on (e.g., 'cuda:0', 'cpu').\n",
    "    - input_shape: The shape of the dummy input tensor for the model.\n",
    "    - dtype: The data type of the dummy input tensor.\n",
    "    - warmup_iters: Number of iterations to warm up the model (important for GPUs).\n",
    "    - measure_iters: Number of iterations to measure the latency.\n",
    "\n",
    "    Returns:\n",
    "    - The average latency in milliseconds of a single forward pass.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move model to the specified device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Generate a dummy input tensor\n",
    "    dummy_input = torch.randn(input_shape, dtype=dtype, device=device)\n",
    "    \n",
    "    # Warm-up phase\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup_iters):\n",
    "            _ = model(dummy_input)\n",
    "    \n",
    "    # Measurement phase\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(measure_iters):\n",
    "            _ = model(dummy_input)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate average latency\n",
    "    avg_latency = (end_time - start_time) / measure_iters * 1000.0  # Convert to milliseconds\n",
    "    \n",
    "    return avg_latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b388aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Union, List\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def random_search(\n",
    "        trained_supernet: nn.Module,\n",
    "        train_dataloader: DataLoader,\n",
    "        val_dataloader: DataLoader,\n",
    "        device: torch.device,\n",
    "        n_architectures_to_test: int,\n",
    "        target_latency: float,) -> Union[float, List[float]]:\n",
    "    # TODO: Implement Random search.\n",
    "    # This function should evaluate `n_architectures_to_test` architectures\n",
    "    # using the `trained_supernet` on the whole validation dataset. The resulting\n",
    "    # architecture should have latency not greater than `target_latency`.\n",
    "    # Rank architectures by validation accuracy.\n",
    "    best_accuracy = 0.0\n",
    "    best_architecture = []\n",
    "    \n",
    "    for _ in tqdm(range(n_architectures_to_test)):\n",
    "        # Sample a random architecture\n",
    "        trained_supernet.sample_random_architecture()\n",
    "        current_architecture = [block.active_op_index for block in trained_supernet.search_blocks]\n",
    "        \n",
    "        # Measure its latency\n",
    "        current_latency = measure_latency(trained_supernet, device)\n",
    "        \n",
    "        # Skip this architecture if it exceeds the target latency\n",
    "        if current_latency > target_latency:\n",
    "            continue\n",
    "        \n",
    "        # Evaluate the architecture\n",
    "        trained_supernet.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = trained_supernet(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        \n",
    "        # Update best architecture if this one is better\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_architecture = current_architecture\n",
    "    \n",
    "    return best_accuracy, best_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "798944f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:44<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best architecture: [0, 2, 2, 2, 2, 0, 1, 1] (test_accuracy=83.930%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_architectures_to_test = 100\n",
    "target_latency = 20 * 1e6\n",
    "\n",
    "accuracy, best_architecture = random_search(supernet, train_dataloader, test_dataloader, device, n_architectures_to_test, target_latency)\n",
    "print(f'best architecture: {best_architecture} (test_accuracy={accuracy:.3%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2a50e",
   "metadata": {},
   "source": [
    "## Train found architecture from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e45eb2d",
   "metadata": {},
   "source": [
    "Go to `Create your baseline model` section.\n",
    "\n",
    "Change model definition to this to build unitialized best architecture from the search space:\n",
    "\n",
    "```python\n",
    "model = supernet18(num_classes=10, zero_init_residual=True, channel_multipliers=channel_multipliers)\n",
    "model.to(device=device)\n",
    "model.sample(best_architecture)\n",
    "```\n",
    "\n",
    "After this, simply run all the cells in that section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d15fa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "Number of macs: 32.20M, number of parameters: 9.43M\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=0, lr=0.2485 loss=2.380: 100%|██████████| 97/97 [00:02<00:00, 45.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3804, train_accuracy=9.200%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=0, loss=2.386: 100%|██████████| 20/20 [00:00<00:00, 67.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3862, test_accuracy=8.120%\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=1, lr=0.2439 loss=2.378: 100%|██████████| 97/97 [00:02<00:00, 46.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3781, train_accuracy=9.351%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=1, loss=2.387: 100%|██████████| 20/20 [00:00<00:00, 69.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3869, test_accuracy=8.050%\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=2, lr=0.2364 loss=2.382: 100%|██████████| 97/97 [00:02<00:00, 45.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3818, train_accuracy=9.190%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=2, loss=2.387: 100%|██████████| 20/20 [00:00<00:00, 64.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3869, test_accuracy=8.130%\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=3, lr=0.2261 loss=2.382: 100%|██████████| 97/97 [00:02<00:00, 44.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3815, train_accuracy=9.158%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=3, loss=2.385: 100%|██████████| 20/20 [00:00<00:00, 68.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3854, test_accuracy=8.070%\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=4, lr=0.2134 loss=2.378: 100%|██████████| 97/97 [00:02<00:00, 43.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3783, train_accuracy=9.248%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=4, loss=2.387: 100%|██████████| 20/20 [00:00<00:00, 69.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3865, test_accuracy=8.050%\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=5, lr=0.1985 loss=2.382: 100%|██████████| 97/97 [00:02<00:00, 45.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3819, train_accuracy=9.119%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=5, loss=2.386: 100%|██████████| 20/20 [00:00<00:00, 65.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3858, test_accuracy=7.970%\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=6, lr=0.1817 loss=2.379: 100%|██████████| 97/97 [00:02<00:00, 44.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3795, train_accuracy=9.472%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=6, loss=2.387: 100%|██████████| 20/20 [00:00<00:00, 73.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3874, test_accuracy=8.110%\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=7, lr=0.1636 loss=2.379: 100%|██████████| 97/97 [00:02<00:00, 44.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3790, train_accuracy=9.403%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=7, loss=2.386: 100%|██████████| 20/20 [00:00<00:00, 66.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3864, test_accuracy=8.160%\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=8, lr=0.1446 loss=2.381: 100%|██████████| 97/97 [00:02<00:00, 45.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3808, train_accuracy=9.411%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=8, loss=2.385: 100%|██████████| 20/20 [00:00<00:00, 63.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3851, test_accuracy=7.970%\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=9, lr=0.1250 loss=2.380: 100%|██████████| 97/97 [00:02<00:00, 45.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3798, train_accuracy=9.343%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=9, loss=2.388: 100%|██████████| 20/20 [00:00<00:00, 56.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3875, test_accuracy=8.050%\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=10, lr=0.1054 loss=2.379: 100%|██████████| 97/97 [00:02<00:00, 45.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3789, train_accuracy=9.220%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=10, loss=2.386: 100%|██████████| 20/20 [00:00<00:00, 59.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3862, test_accuracy=8.060%\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=11, lr=0.0864 loss=2.381: 100%|██████████| 97/97 [00:02<00:00, 43.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3815, train_accuracy=9.319%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=11, loss=2.385: 100%|██████████| 20/20 [00:00<00:00, 70.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3853, test_accuracy=8.110%\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=12, lr=0.0683 loss=2.379: 100%|██████████| 97/97 [00:02<00:00, 44.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3792, train_accuracy=9.379%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=12, loss=2.385: 100%|██████████| 20/20 [00:00<00:00, 67.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3852, test_accuracy=8.120%\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=13, lr=0.0515 loss=2.380: 100%|██████████| 97/97 [00:02<00:00, 44.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3795, train_accuracy=9.431%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=13, loss=2.387: 100%|██████████| 20/20 [00:00<00:00, 61.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3866, test_accuracy=8.040%\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=14, lr=0.0366 loss=2.380: 100%|██████████| 97/97 [00:02<00:00, 45.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3801, train_accuracy=9.168%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=14, loss=2.386: 100%|██████████| 20/20 [00:00<00:00, 74.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3863, test_accuracy=8.150%\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=15, lr=0.0239 loss=2.379: 100%|██████████| 97/97 [00:02<00:00, 44.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3794, train_accuracy=9.353%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=15, loss=2.386: 100%|██████████| 20/20 [00:00<00:00, 62.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3863, test_accuracy=8.060%\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=16, lr=0.0136 loss=2.380: 100%|██████████| 97/97 [00:02<00:00, 44.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3804, train_accuracy=9.214%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=16, loss=2.385: 100%|██████████| 20/20 [00:00<00:00, 60.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3852, test_accuracy=8.030%\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=17, lr=0.0061 loss=2.379: 100%|██████████| 97/97 [00:02<00:00, 44.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3790, train_accuracy=9.309%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=17, loss=2.386: 100%|██████████| 20/20 [00:00<00:00, 64.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3856, test_accuracy=8.150%\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=18, lr=0.0015 loss=2.380: 100%|██████████| 97/97 [00:02<00:00, 43.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3799, train_accuracy=9.174%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=18, loss=2.387: 100%|██████████| 20/20 [00:00<00:00, 69.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3872, test_accuracy=8.040%\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=19, lr=0.0000 loss=2.377: 100%|██████████| 97/97 [00:02<00:00, 42.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.3773, train_accuracy=9.228%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=19, loss=2.386: 100%|██████████| 20/20 [00:00<00:00, 64.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=2.3863, test_accuracy=8.120%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_architecture = [2, 2, 1, 2, 1, 0, 1, 2]\n",
    "model = supernet18(num_classes=10, zero_init_residual=True, channel_multipliers=channel_multipliers)\n",
    "model.to(device=device)\n",
    "model.sample(best_architecture)\n",
    "\n",
    "macs, params = profile(model, inputs=(torch.zeros(1, 3, 32, 32, device=device),))\n",
    "print(f'Number of macs: {macs / 1e6:.2f}M, number of parameters: {params / 1e6:.2f}M')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    loss, accuracy = train_one_epoch(model, criterion, train_dataloader, optimizer, scheduler, device, epoch)\n",
    "    print(f'train_loss={loss:.4f}, train_accuracy={accuracy:.3%}')\n",
    "    loss, accuracy = validate_one_epoch(model, criterion, test_dataloader, device, epoch)\n",
    "    print(f'test_loss={loss:.4f}, test_accuracy={accuracy:.3%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
