{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to implement SPOS + Random Search to find the optimal ResNet-18-like architecture\n",
    "for image classification on CIFAR-10 dataset.\n",
    "\n",
    "### Proposed search space\n",
    "The same search space as in the lecture, but without kernel size search.\n",
    "This means that each search block should only have 3 operations.\n",
    "\n",
    "### Latency awareness\n",
    "While searching, you should implement hard constraint on model latency. As a proxy for\n",
    "latency, use the number of MACs. The baseline ResNet-18 has 37M MACs for images of size 32x32.\n",
    "The final selected architecture should have at most 30M MACs.\n",
    "You can find an example computation for the number of MACs in this notebook.\n",
    "\n",
    "### How to complete the task\n",
    "Plan for your experiments:\n",
    "1. Train baseline ResNet-18 model.  **(2 pts)**\n",
    "2. Finalize supernet code. **(15 pts)**\n",
    "3. Train supernet with the same hyperparameters except the number of epochs. You should increase\n",
    "   it by a factor of 3-6. Save supernet weights.  **(10 pts)**\n",
    "4. Write implementation for Random Search.  **(10 pts)**\n",
    "5. Run it for 100-1000 iterations by measuring accuracies of models from the supernet.\n",
    "   Keep track of each model accuracy and latency.  **(5 pts)**\n",
    "6. Train the best architecture from scratch. For this, you can build the whole supernet, and\n",
    "   select this architecture for all the forward passes of the training.  **(6 pts)**\n",
    "7. Compare with the model from step 1. Does your model have a better accuracy?  **(2 pts)**\n",
    "\n",
    "### Code structure\n",
    "\n",
    "Main.ipynb - Learn your neural networks here.\n",
    "\n",
    "resnet.py - ResNet-18 implementation from torchvision, simplified for this project.\n",
    "\n",
    "supernet.py - Unfinished Supernet implementation.\n",
    "\n",
    "cifar10.py - Transforms for CIFAR-10 training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/gvasserm/.local/lib/python3.10/site-packages (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision in /home/gvasserm/.local/lib/python3.10/site-packages (0.17.1+cu121)\n",
      "Requirement already satisfied: numpy in /home/gvasserm/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: thop in /home/gvasserm/.local/lib/python3.10/site-packages (0.1.1.post2209072238)\n",
      "Requirement already satisfied: tqdm in /home/gvasserm/.local/lib/python3.10/site-packages (4.66.2)\n",
      "Requirement already satisfied: filelock in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/gvasserm/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/gvasserm/.local/lib/python3.10/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gvasserm/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/gvasserm/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision numpy thop tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from thop import profile\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cifar10 import get_train_transform, get_val_transform\n",
    "from resnet import resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make everything a bit faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this value if needed.\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_transform = get_train_transform()\n",
    "val_transform = get_val_transform()\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform,\n",
    ")\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select suitable device.\n",
    "# You should probably use either cuda (NVidia GPU) or mps (Apple) backend.\n",
    "device = torch.device('cuda:0')\n",
    "model = resnet18(num_classes=10, zero_init_residual=True)\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the number of MACs and parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "Number of macs: 37.22M, number of parameters: 11.18M\n"
     ]
    }
   ],
   "source": [
    "macs, params = profile(model, inputs=(torch.zeros(1, 3, 32, 32, device=device),))\n",
    "print(f'Number of macs: {macs / 1e6:.2f}M, number of parameters: {params / 1e6:.2f}M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.25\n",
    "weight_decay = 5e-4\n",
    "momentum = 0.9\n",
    "n_epochs = 20  # Longer training gives better results, but let's keep baseline model epochs to 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_dataloader) * n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        optimizer: optim.Optimizer,\n",
    "        scheduler,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in wrapped_dataloader:\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (predicted_labels == labels).sum().item()\n",
    "            total_samples += labels.shape[0]\n",
    "\n",
    "        wrapped_dataloader.set_description(\n",
    "            f'(train) Epoch={epoch}, lr={scheduler.get_last_lr()[0]:.4f} loss={total_loss / (i + 1):.3f}'\n",
    "        )\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        dataloader: DataLoader,\n",
    "        device: torch.device,\n",
    "        epoch: int,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    wrapped_dataloader = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, (inputs, labels) in wrapped_dataloader:\n",
    "        inputs = inputs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (predicted_labels == labels).sum().item()\n",
    "        total_samples += labels.shape[0]\n",
    "\n",
    "        wrapped_dataloader.set_description(f'(val) Epoch={epoch}, loss={total_loss / (i + 1):.3f}')\n",
    "\n",
    "    return total_loss / len(dataloader), total_correct / total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=0, lr=0.2485 loss=2.011: 100%|██████████| 97/97 [00:03<00:00, 31.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=2.0107, train_accuracy=28.328%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=0, loss=1.589: 100%|██████████| 20/20 [00:00<00:00, 49.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.5893, test_accuracy=38.970%\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=1, lr=0.2439 loss=1.426: 100%|██████████| 97/97 [00:02<00:00, 39.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.4255, train_accuracy=47.993%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=1, loss=1.332: 100%|██████████| 20/20 [00:00<00:00, 65.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.3316, test_accuracy=52.200%\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=2, lr=0.2364 loss=1.208: 100%|██████████| 97/97 [00:02<00:00, 39.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.2076, train_accuracy=56.550%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=2, loss=1.112: 100%|██████████| 20/20 [00:00<00:00, 69.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.1122, test_accuracy=60.690%\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=3, lr=0.2261 loss=1.078: 100%|██████████| 97/97 [00:02<00:00, 39.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=1.0785, train_accuracy=61.554%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=3, loss=1.007: 100%|██████████| 20/20 [00:00<00:00, 61.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=1.0069, test_accuracy=64.310%\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=4, lr=0.2134 loss=0.982: 100%|██████████| 97/97 [00:02<00:00, 39.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.9821, train_accuracy=65.140%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=4, loss=0.978: 100%|██████████| 20/20 [00:00<00:00, 67.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.9778, test_accuracy=66.080%\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=5, lr=0.1985 loss=0.908: 100%|██████████| 97/97 [00:02<00:00, 40.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.9080, train_accuracy=67.834%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=5, loss=0.911: 100%|██████████| 20/20 [00:00<00:00, 51.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.9110, test_accuracy=68.490%\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=6, lr=0.1817 loss=0.871: 100%|██████████| 97/97 [00:02<00:00, 39.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.8713, train_accuracy=69.137%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=6, loss=0.864: 100%|██████████| 20/20 [00:00<00:00, 63.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.8635, test_accuracy=69.830%\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=7, lr=0.1636 loss=0.815: 100%|██████████| 97/97 [00:02<00:00, 38.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.8147, train_accuracy=71.545%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=7, loss=0.890: 100%|██████████| 20/20 [00:00<00:00, 62.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.8904, test_accuracy=69.710%\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=8, lr=0.1446 loss=0.761: 100%|██████████| 97/97 [00:02<00:00, 39.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.7611, train_accuracy=73.409%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=8, loss=0.789: 100%|██████████| 20/20 [00:00<00:00, 66.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7886, test_accuracy=73.120%\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=9, lr=0.1250 loss=0.721: 100%|██████████| 97/97 [00:02<00:00, 38.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.7208, train_accuracy=74.644%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=9, loss=0.892: 100%|██████████| 20/20 [00:00<00:00, 56.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.8918, test_accuracy=69.960%\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=10, lr=0.1054 loss=0.683: 100%|██████████| 97/97 [00:02<00:00, 39.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6827, train_accuracy=76.152%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=10, loss=0.658: 100%|██████████| 20/20 [00:00<00:00, 66.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.6577, test_accuracy=77.320%\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=11, lr=0.0864 loss=0.637: 100%|██████████| 97/97 [00:02<00:00, 39.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.6372, train_accuracy=77.523%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=11, loss=0.719: 100%|██████████| 20/20 [00:00<00:00, 55.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.7194, test_accuracy=75.900%\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(train) Epoch=12, lr=0.0683 loss=0.595: 100%|██████████| 97/97 [00:02<00:00, 39.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.5948, train_accuracy=79.164%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=12, loss=0.636: 100%|██████████| 20/20 [00:00<00:00, 62.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.6361, test_accuracy=78.270%\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=13, lr=0.0515 loss=0.557: 100%|██████████| 97/97 [00:02<00:00, 39.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.5569, train_accuracy=80.600%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=13, loss=0.606: 100%|██████████| 20/20 [00:00<00:00, 60.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.6058, test_accuracy=79.440%\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=14, lr=0.0366 loss=0.519: 100%|██████████| 97/97 [00:02<00:00, 38.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.5191, train_accuracy=81.731%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=14, loss=0.562: 100%|██████████| 20/20 [00:00<00:00, 62.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5621, test_accuracy=81.040%\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=15, lr=0.0239 loss=0.480: 100%|██████████| 97/97 [00:02<00:00, 37.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4798, train_accuracy=83.209%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=15, loss=0.542: 100%|██████████| 20/20 [00:00<00:00, 62.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5417, test_accuracy=81.410%\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=16, lr=0.0136 loss=0.448: 100%|██████████| 97/97 [00:03<00:00, 31.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4484, train_accuracy=84.427%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=16, loss=0.524: 100%|██████████| 20/20 [00:00<00:00, 62.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5244, test_accuracy=82.420%\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=17, lr=0.0061 loss=0.418: 100%|██████████| 97/97 [00:03<00:00, 30.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4179, train_accuracy=85.265%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=17, loss=0.511: 100%|██████████| 20/20 [00:00<00:00, 56.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5114, test_accuracy=82.670%\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=18, lr=0.0015 loss=0.400: 100%|██████████| 97/97 [00:03<00:00, 31.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.4002, train_accuracy=86.072%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=18, loss=0.509: 100%|██████████| 20/20 [00:00<00:00, 60.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5090, test_accuracy=82.660%\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(train) Epoch=19, lr=0.0000 loss=0.397: 100%|██████████| 97/97 [00:03<00:00, 30.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.3969, train_accuracy=86.203%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(val) Epoch=19, loss=0.508: 100%|██████████| 20/20 [00:00<00:00, 62.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss=0.5080, test_accuracy=82.780%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    loss, accuracy = train_one_epoch(model, criterion, train_dataloader, optimizer, scheduler, device, epoch)\n",
    "    print(f'train_loss={loss:.4f}, train_accuracy={accuracy:.3%}')\n",
    "    loss, accuracy = validate_one_epoch(model, criterion, test_dataloader, device, epoch)\n",
    "    print(f'test_loss={loss:.4f}, test_accuracy={accuracy:.3%}')\n",
    "\n",
    "torch.save(model.state_dict(), 'baseline_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
