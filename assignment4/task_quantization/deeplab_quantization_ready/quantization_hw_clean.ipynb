{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14864c63-1ec1-456d-a026-786f650f4f16",
   "metadata": {},
   "source": [
    "### Квантует DeepLabV3 MobilenetV3\n",
    "\n",
    "Стартуем с трейнлупа, который нам выдали pytorch\n",
    "\n",
    "Датасет COCO, https://cocodataset.org/#download \n",
    "Качаем train2017 и val2017\n",
    "\n",
    "Можно использовать [сабсет](https://drive.google.com/file/d/1qdtAbK-iOsgJZxjbBva0pw2Vi5penjPc/view?usp=sharing) трейна на 20000, но тогда заранее залезте в класс датасета, и добавте работу с пропущенными картинками\n",
    "\n",
    "Баллы: 20 баллов Static Quantization + 20 баллов Quantization Aware Training + 10 баллов Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf7a00-f092-413e-9789-7fe81046d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch.ao.quantization.quantize_fx import convert_fx\n",
    "from torch.ao.quantization.quantize_fx import fuse_fx\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "from torchvision.models.segmentation import DeepLabV3_MobileNet_V3_Large_Weights, deeplabv3_mobilenet_v3_large\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "from quantization_utils.fake_quantization import fake_quantization\n",
    "from quantization_utils.static_quantization import quantize_static\n",
    "from train import evaluate\n",
    "from train import get_dataset\n",
    "from train import train_one_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf831e0a-003e-40fb-9b3f-ad1a225751c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вытащил дефолтные аргументы, чтобы не упражняться с argparse в ноутбуке\n",
    "with Path('./torch_default_args.pickle').open('rb') as file:\n",
    "    args = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb1e03-f5fc-4ec4-a089-54f464c17b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подобирайте под ваше железо\n",
    "args.data_path = '/home/d.chudakov/datasets/coco/'\n",
    "args.epochs = 1\n",
    "args.batch_size = 32\n",
    "args.workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b93ea-21fc-4e72-8bab-e16d8722fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d07a33-dd10-41d5-84f2-6c3c6cc22971",
   "metadata": {},
   "source": [
    "### Сначала просто валидация обычной сетки, прям на гпу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddaa10-5909-451b-ae90-6ee0f013da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deeplabv3_mobilenet_v3_large(weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15585f-78f7-4437-8f14-aea099b82f3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.output_dir:\n",
    "    utils.mkdir(args.output_dir)\n",
    "\n",
    "utils.init_distributed_mode(args)\n",
    "\n",
    "device = torch.device(args.device)\n",
    "\n",
    "dataset_test, num_classes = get_dataset(args, is_train=False)\n",
    "\n",
    "test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=32, sampler=test_sampler, num_workers=args.workers, collate_fn=utils.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c78a1-6a74-48ec-938c-d511918645f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "model.cuda()\n",
    "confmat = evaluate(model, data_loader_test, device=device, num_classes=num_classes)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4465c3c9-0eb8-46d4-ae0d-79336cd1b7c9",
   "metadata": {},
   "source": [
    "### Заквантуем статические сетку, посмотрим на точность и скорость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfca70-948a-4e42-b7c9-2a9984108f83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Квантуем\n",
    "# Делаем fuse, делаем quantize_static и quantize_utils (посмотрите что там с кодом)\n",
    "# Можно покрутить параметр num_batches, чтобы посмотреть сколько нужно данных на калибровку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e8eda0-19fc-4a50-8a7a-9aa9f7f79391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замерим скорость квантованной модели на CPU\n",
    "# Не забываем, от размера батча будет зависить буст!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae59f5e2-9fa3-4d39-ba25-13817a65a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замеряем с бачтом 1, буста нет\n",
    "# Замеряем с батчом 32, буст есть\n",
    "# Мораль, latency != throughput. В сетке всегда есть накладные расходы, кроме перемалывания матричек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a60bf-6fb1-4b14-b44e-d06efb9c9f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замерим скорость оригинальной модели на CPU\n",
    "# У меня на intel i9 при батчсайзе 32 получился x2 буст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e66e00-55a3-4ddf-b376-07e402ff9bbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Посчитаем метрики квантованной модели\n",
    "# У меня была просадка где-то до 56 IoU\n",
    "q_model.cpu()\n",
    "confmat = evaluate(q_model, data_loader_test, device='cpu', num_classes=num_classes)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e149e-08b7-4f90-b3a7-e312adb6ece8",
   "metadata": {},
   "source": [
    "### Делаем Quantization Aware Training. Используем готовый трейнплуп от pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de375f28-bf82-4c3a-924d-03c3a75376e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Делаем фейк квантование, идём смотреть quantization_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6d85d-82cc-4d99-81de-3d12a9e6e375",
   "metadata": {},
   "source": [
    "### Тут берём из train.py скрипт main() и вытаскиваем трейн луп"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d671589-a9e9-4459-a59a-b4cea6f653b5",
   "metadata": {},
   "source": [
    "1. Не забыть провалидировать модель fake quant до qat\n",
    "2. Не забыть провалидировать модель после обучения\n",
    "3. Конвертировать модель из fake quant в обычный quant\n",
    "4. Проверить точность и скорость модели\n",
    "Должно хватить пары эпох, lr надо будет покрутить.\n",
    "Цель минимум это поднять точность конвертированной QAT модели (будет у вас QAT до обучения 55, станет 56, молодцы!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8b72c-76c2-4480-a1b1-8f7ee33e5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подсказка, учить надо в train и на GPU\n",
    "qat_model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa71d29-c5bf-47fd-9d62-593345f76cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инференс делаем на cpu, предварительно конвертируя модельку на CPU\n",
    "qat_model.cpu()\n",
    "int_qat_model = convert_fx(qat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e30de-5a6a-45a2-bf7e-27b6ac3c9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Точность модели fake quant и квантованной после конвертации будут разные\n",
    "# Так и должно быть, всё таки мы эмулировали квантование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3213cc-9a38-44dd-a35e-f4f0f79db8bb",
   "metadata": {},
   "source": [
    "### Балуемся с дистилляцией\n",
    "Врываемся в train.py и добавляем туда дистилляцию, просто по последнему слою (до софтмакса, на логитах) делаем стягивание по MSE\n",
    "\n",
    "Цель поднять точность и ускорить сходимость.\n",
    "\n",
    "Балуемся с весами обычного и distill лосса.\n",
    "\n",
    "Можно вообще выкинуть classification loss и смоделировать ситуацию когда вам не выдали лейблов (жиза)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f1a2f-76c2-48d5-ac99-040460da12a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
