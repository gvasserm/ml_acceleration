{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03044e0e",
   "metadata": {},
   "source": [
    "Перед началом выполнения задания, нужно поставить все зависимости, для этого нужно установить requirements.\n",
    "pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f0e97",
   "metadata": {},
   "source": [
    "# Перед выполнением нужно установить \"adb\" с помощью коменды \"apt install adb\", и разрешить дебаг через usb на телефоне. Для этого нужно:\n",
    "1. Перевести телефон в режим разработчика( Настройки > О телефоне > Версия ПО > Дополнительно, далее нажать 7 раз на номер сборки.)\n",
    "2. в Меню разработчика разрешить отладку по usb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba732824",
   "metadata": {},
   "source": [
    "Баллы:\n",
    "dynamic квантование - 10 + 10\n",
    "Замена HardSwish - 15\n",
    "Замена HardSigmoid - 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a67c20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 11:19:40.440714: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-13 11:19:40.466980: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-13 11:19:40.467001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-13 11:19:40.467720: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-13 11:19:40.472200: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 11:19:40.953009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from torchvision.models.segmentation import DeepLabV3_MobileNet_V3_Large_Weights\n",
    "from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45d4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# качаем модельку \n",
    "model = deeplabv3_mobilenet_v3_large(weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f1c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем модельку в onnx\n",
    "input_tensor = torch.rand((1, 3, 300, 300))\n",
    "with torch.no_grad():\n",
    "    output_fixed = model(input_tensor)['out']\n",
    "\n",
    "torch.onnx.export(model, input_tensor, f=f\"dv3_mnv3.onnx\", export_params=True, input_names=['input'], \n",
    "                  do_constant_folding=True, opset_version=13, output_names=['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1677584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
      "\u001b[1;35mInstalling onnxruntime by `/usr/bin/python3 -m pip install onnxruntime`, please \u001b[0m\n",
      "\u001b[1;35mwait for a moment..\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /home/gvasserm/.local/lib/python3.10/site-packages (from onnxruntime) (24.3.25)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/gvasserm/.local/lib/python3.10/site-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/gvasserm/.local/lib/python3.10/site-packages (from onnxruntime) (24.0)\n",
      "Requirement already satisfied: protobuf in /home/gvasserm/.local/lib/python3.10/site-packages (from onnxruntime) (4.25.3)\n",
      "Requirement already satisfied: sympy in /home/gvasserm/.local/lib/python3.10/site-packages (from onnxruntime) (1.12)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/gvasserm/.local/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.3\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add               │ 10             │ 10               │\n",
      "│ Concat            │ 4              │ \u001b[1;32m1               \u001b[0m │\n",
      "│ Constant          │ 156            │ \u001b[1;32m146             \u001b[0m │\n",
      "│ Conv              │ 72             │ 72               │\n",
      "│ GlobalAveragePool │ 9              │ 9                │\n",
      "│ HardSigmoid       │ 28             │ 28               │\n",
      "│ Mul               │ 28             │ 28               │\n",
      "│ Relu              │ 27             │ 27               │\n",
      "│ Resize            │ 3              │ 3                │\n",
      "│ Shape             │ 3              │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Slice             │ 3              │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Model Size        │ 42.1MiB        │ \u001b[1;32m42.1MiB         \u001b[0m │\n",
      "└───────────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add               │ 10             │ 10               │\n",
      "│ Concat            │ 1              │ 1                │\n",
      "│ Constant          │ 146            │ 146              │\n",
      "│ Conv              │ 72             │ 72               │\n",
      "│ GlobalAveragePool │ 9              │ 9                │\n",
      "│ HardSigmoid       │ 28             │ 28               │\n",
      "│ Mul               │ 28             │ 28               │\n",
      "│ Relu              │ 27             │ 27               │\n",
      "│ Resize            │ 3              │ 3                │\n",
      "│ Model Size        │ 42.1MiB        │ 42.1MiB          │\n",
      "└───────────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add               │ 10             │ 10               │\n",
      "│ Concat            │ 1              │ 1                │\n",
      "│ Constant          │ 146            │ 146              │\n",
      "│ Conv              │ 72             │ 72               │\n",
      "│ GlobalAveragePool │ 9              │ 9                │\n",
      "│ HardSigmoid       │ 28             │ 28               │\n",
      "│ Mul               │ 28             │ 28               │\n",
      "│ Relu              │ 27             │ 27               │\n",
      "│ Resize            │ 3              │ 3                │\n",
      "│ Model Size        │ 42.1MiB        │ 42.1MiB          │\n",
      "└───────────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "\u001b[32mModel optimizing complete!\u001b[0m\n",
      "\n",
      "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
      "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
      "\n",
      "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
      "\n",
      "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: input \u001b[32mshape\u001b[0m: [1, 3, 300, 300] \u001b[32mdtype\u001b[0m: float32\n",
      "\u001b[33mWARNING:\u001b[0m The optimization process for shape estimation is skipped because it contains OPs that cannot be inferred by the standard onnxruntime.\n",
      "\u001b[33mWARNING:\u001b[0m name 'ort' is not defined\n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m2 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.0/backbone.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input \u001b[36mshape\u001b[0m: [1, 3, 300, 300] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_640 \u001b[36mshape\u001b[0m: [16, 3, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_641 \u001b[36mshape\u001b[0m: [16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 302, 302, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 3, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (16,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m3 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.0/backbone.0.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum/Maximum:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m4 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum/Maximum:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_3/Mul:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m5 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_643 \u001b[36mshape\u001b[0m: [16, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_644 \u001b[36mshape\u001b[0m: [16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_3/Mul:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 16, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (16,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 16 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m6 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m7 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.1/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_646 \u001b[36mshape\u001b[0m: [16, 16, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_647 \u001b[36mshape\u001b[0m: [16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.1/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 16, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (16,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m8 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.1/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.1/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_3/Mul:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m9 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_649 \u001b[36mshape\u001b[0m: [64, 16, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_650 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 16, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m10 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m11 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_652 \u001b[36mshape\u001b[0m: [64, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_653 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_1/Pad:0 \u001b[34mshape\u001b[0m: (1, 152, 152, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 64 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m12 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_5/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m13 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.2/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_655 \u001b[36mshape\u001b[0m: [24, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_656 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.2/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m14 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.2/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_658 \u001b[36mshape\u001b[0m: [72, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_659 \u001b[36mshape\u001b[0m: [72] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (72,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m15 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m16 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_661 \u001b[36mshape\u001b[0m: [72, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_662 \u001b[36mshape\u001b[0m: [72] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 72, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (72,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 72 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m17 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m18 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_664 \u001b[36mshape\u001b[0m: [24, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_665 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 72, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m19 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.2/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/Add_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_10/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m20 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/Add_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_667 \u001b[36mshape\u001b[0m: [72, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_668 \u001b[36mshape\u001b[0m: [72] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_10/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (72,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m21 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_5/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m22 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_670 \u001b[36mshape\u001b[0m: [72, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_671 \u001b[36mshape\u001b[0m: [72] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_2/Pad:0 \u001b[34mshape\u001b[0m: (1, 79, 79, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 72, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (72,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 72 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m23 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m24 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m25 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.4.block.2.fc1.weight \u001b[36mshape\u001b[0m: [24, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.4.block.2.fc1.bias \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 72, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m26 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m27 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.4.block.2.fc2.weight \u001b[36mshape\u001b[0m: [72, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.4.block.2.fc2.bias \u001b[36mshape\u001b[0m: [72] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (72,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m28 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_1/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m29 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_1/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_11/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m30 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_673 \u001b[36mshape\u001b[0m: [40, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_674 \u001b[36mshape\u001b[0m: [40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_11/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 72, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (40,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m31 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_676 \u001b[36mshape\u001b[0m: [120, 40, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_677 \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 40, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m32 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/aux_classifier/aux_classifier.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_799 \u001b[36mshape\u001b[0m: [10, 40, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_800 \u001b[36mshape\u001b[0m: [10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/aux_classifier/aux_classifier.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 10, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 40, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (10,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m33 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m34 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/aux_classifier/aux_classifier.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/aux_classifier/aux_classifier.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 10, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/aux_classifier/aux_classifier.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 10, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m35 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_679 \u001b[36mshape\u001b[0m: [120, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_680 \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 120, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 120 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m36 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/aux_classifier/aux_classifier.4/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/aux_classifier/aux_classifier.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 10, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: aux_classifier.4.weight \u001b[36mshape\u001b[0m: [21, 10, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: aux_classifier.4.bias \u001b[36mshape\u001b[0m: [21] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/aux_classifier/aux_classifier.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 21, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 10, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (21,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m37 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m38 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: wa/Resize_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/aux_classifier/aux_classifier.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 21, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/Concat_1_output_0 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: 638 \u001b[36mshape\u001b[0m: [1, 21, 300, 300] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_bilinear\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mshape\u001b[0m: (2,) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: bilinear \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.image.resize_bilinear/ResizeBilinear:0 \u001b[34mshape\u001b[0m: (1, 300, 300, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m39 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_1/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m40 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.5.block.2.fc1.weight \u001b[36mshape\u001b[0m: [32, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.5.block.2.fc1.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_1/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 120, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m41 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m42 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.5.block.2.fc2.weight \u001b[36mshape\u001b[0m: [120, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.5.block.2.fc2.bias \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m43 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_2/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m44 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_2/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_15/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m45 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_682 \u001b[36mshape\u001b[0m: [40, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_683 \u001b[36mshape\u001b[0m: [40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_15/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 120, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (40,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m46 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.4/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/Add_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m47 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/Add_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_685 \u001b[36mshape\u001b[0m: [120, 40, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_686 \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 40, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_24/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m48 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_24/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_12/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m49 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_688 \u001b[36mshape\u001b[0m: [120, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_689 \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_12/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 120, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 120 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m50 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m51 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_2/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m52 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.6.block.2.fc1.weight \u001b[36mshape\u001b[0m: [32, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.6.block.2.fc1.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_2/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 120, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m53 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m54 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.6.block.2.fc2.weight \u001b[36mshape\u001b[0m: [120, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.6.block.2.fc2.bias \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m55 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_3/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m56 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_3/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_21/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m57 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_691 \u001b[36mshape\u001b[0m: [40, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_692 \u001b[36mshape\u001b[0m: [40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_21/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 120, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (40,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_28/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m58 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.5/Add_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/Add_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_28/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_29/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m59 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/Add_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_694 \u001b[36mshape\u001b[0m: [240, 40, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_695 \u001b[36mshape\u001b[0m: [240] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_29/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 40, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (240,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m60 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_4/Maximum:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m61 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_4/Maximum:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_27/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m62 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_697 \u001b[36mshape\u001b[0m: [240, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_698 \u001b[36mshape\u001b[0m: [240] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_3/Pad:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 240, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (240,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 240 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m63 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_5/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m64 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_5/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_31/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m65 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_700 \u001b[36mshape\u001b[0m: [80, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_701 \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_31/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 240, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m66 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_703 \u001b[36mshape\u001b[0m: [200, 80, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_704 \u001b[36mshape\u001b[0m: [200] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 80, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (200,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m67 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_6/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m68 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_6/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_35/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m69 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_706 \u001b[36mshape\u001b[0m: [200, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_707 \u001b[36mshape\u001b[0m: [200] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_35/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 200, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (200,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 200 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m70 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_7/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m71 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_7/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_39/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m72 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_709 \u001b[36mshape\u001b[0m: [80, 200, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_710 \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_39/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 200, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_35/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m73 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.7/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_35/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_36/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m74 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_712 \u001b[36mshape\u001b[0m: [184, 80, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_713 \u001b[36mshape\u001b[0m: [184] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_36/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 80, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (184,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_37/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m75 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_37/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_8/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m76 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_37/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_8/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_45/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m77 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_715 \u001b[36mshape\u001b[0m: [184, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_716 \u001b[36mshape\u001b[0m: [184] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_45/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 184, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (184,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 184 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m78 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_9/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m79 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_9/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_49/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m80 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_718 \u001b[36mshape\u001b[0m: [80, 184, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_719 \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_49/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 184, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_39/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m81 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.8/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_39/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_36/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m82 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_721 \u001b[36mshape\u001b[0m: [184, 80, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_722 \u001b[36mshape\u001b[0m: [184] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 80, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (184,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m83 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_10/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m84 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_10/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_55/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m85 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_724 \u001b[36mshape\u001b[0m: [184, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_725 \u001b[36mshape\u001b[0m: [184] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_55/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 184, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (184,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 184 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m86 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_11/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m87 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_11/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_59/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m88 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_727 \u001b[36mshape\u001b[0m: [80, 184, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_728 \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_59/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 184, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_43/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m89 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.9/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_43/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m90 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_730 \u001b[36mshape\u001b[0m: [480, 80, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_731 \u001b[36mshape\u001b[0m: [480] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 80, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (480,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m91 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_12/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m92 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_12/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_65/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m93 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_733 \u001b[36mshape\u001b[0m: [480, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_734 \u001b[36mshape\u001b[0m: [480] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_65/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 480, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (480,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 480 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m94 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_13/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m95 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_13/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_69/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m96 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_69/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_3/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m97 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.11.block.2.fc1.weight \u001b[36mshape\u001b[0m: [120, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.11.block.2.fc1.bias \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_3/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 480, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_47/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m98 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_47/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_15/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m99 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.11.block.2.fc2.weight \u001b[36mshape\u001b[0m: [480, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.11.block.2.fc2.bias \u001b[36mshape\u001b[0m: [480] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_15/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 120, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (480,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m100 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_14/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m101 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_14/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_69/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_73/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m102 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_736 \u001b[36mshape\u001b[0m: [112, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_737 \u001b[36mshape\u001b[0m: [112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_73/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 480, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (112,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m103 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_739 \u001b[36mshape\u001b[0m: [672, 112, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_740 \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 112, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_50/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m104 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_50/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_15/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m105 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_50/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_15/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_77/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m106 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_742 \u001b[36mshape\u001b[0m: [672, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_743 \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_77/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 672, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 672 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_51/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m107 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_51/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_16/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m108 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_51/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_16/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_81/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m109 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_81/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_4/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m110 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.12.block.2.fc1.weight \u001b[36mshape\u001b[0m: [168, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.12.block.2.fc1.bias \u001b[36mshape\u001b[0m: [168] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_4/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 672, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (168,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m111 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m112 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.12.block.2.fc2.weight \u001b[36mshape\u001b[0m: [672, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.12.block.2.fc2.bias \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 168, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_53/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m113 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_53/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_17/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m114 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_17/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_81/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_85/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m115 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_745 \u001b[36mshape\u001b[0m: [112, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_746 \u001b[36mshape\u001b[0m: [112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_85/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 672, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (112,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m116 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.11/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/Add_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_55/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m117 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/Add_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_748 \u001b[36mshape\u001b[0m: [672, 112, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_749 \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_55/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 112, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_56/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m118 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_56/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_18/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m119 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_56/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_18/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_91/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m120 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_751 \u001b[36mshape\u001b[0m: [672, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_752 \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_91/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 672, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 672 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m121 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_19/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m122 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_19/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_95/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m123 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_95/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_5/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m124 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.13.block.2.fc1.weight \u001b[36mshape\u001b[0m: [168, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.13.block.2.fc1.bias \u001b[36mshape\u001b[0m: [168] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_5/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 672, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (168,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m125 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m126 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.13.block.2.fc2.weight \u001b[36mshape\u001b[0m: [672, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.13.block.2.fc2.bias \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 168, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_59/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m127 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_59/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_20/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m128 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_20/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_95/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_99/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m129 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_754 \u001b[36mshape\u001b[0m: [160, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_755 \u001b[36mshape\u001b[0m: [160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_99/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 672, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (160,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m130 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_757 \u001b[36mshape\u001b[0m: [960, 160, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_758 \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 160, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_61/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m131 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_61/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_21/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m132 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_61/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_21/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_103/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m133 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_760 \u001b[36mshape\u001b[0m: [960, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_761 \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_103/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 960, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 960 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_62/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m134 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_62/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_22/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m135 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_62/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_22/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_107/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m136 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_107/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_6/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m137 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.14.block.2.fc1.weight \u001b[36mshape\u001b[0m: [240, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.14.block.2.fc1.bias \u001b[36mshape\u001b[0m: [240] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_6/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (240,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_63/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m138 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_63/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_18/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m139 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.14.block.2.fc2.weight \u001b[36mshape\u001b[0m: [960, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.14.block.2.fc2.bias \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_18/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 240, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_64/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m140 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_64/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_23/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m141 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_23/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_107/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_111/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m142 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_763 \u001b[36mshape\u001b[0m: [160, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_764 \u001b[36mshape\u001b[0m: [160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_111/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (160,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_65/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m143 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.13/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/Add_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_65/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_66/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m144 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/Add_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_766 \u001b[36mshape\u001b[0m: [960, 160, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_767 \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_66/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 160, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_67/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m145 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_67/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_24/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m146 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_67/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_24/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_117/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m147 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_769 \u001b[36mshape\u001b[0m: [960, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_770 \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_117/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 960, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 960 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_68/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m148 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_68/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_25/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m149 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_68/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_25/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_121/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m150 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_121/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_7/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m151 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.15.block.2.fc1.weight \u001b[36mshape\u001b[0m: [240, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.15.block.2.fc1.bias \u001b[36mshape\u001b[0m: [240] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_7/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (240,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_69/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m152 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_69/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_19/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m153 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.15.block.2.fc2.weight \u001b[36mshape\u001b[0m: [960, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.15.block.2.fc2.bias \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_19/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 240, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_70/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m154 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_70/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_26/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m155 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_26/Maximum:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_121/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_125/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m156 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_772 \u001b[36mshape\u001b[0m: [160, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_773 \u001b[36mshape\u001b[0m: [160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_125/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (160,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_71/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m157 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.14/Add_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/Add_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_71/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_66/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_72/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m158 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.16/backbone.16.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/Add_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_775 \u001b[36mshape\u001b[0m: [960, 160, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_776 \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_72/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 160, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_73/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m159 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: HardSigmoid\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.16/backbone.16.2/HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: HardSigmoid\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_73/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_27/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m160 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.16/backbone.16.2/HardSigmoid_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_73/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum_27/Maximum:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_131/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m161 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_778 \u001b[36mshape\u001b[0m: [256, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_779 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_131/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_74/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m162 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_781 \u001b[36mshape\u001b[0m: [256, 960, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_782 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_131/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 960, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [12, 12] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_75/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m163 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_784 \u001b[36mshape\u001b[0m: [256, 960, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_785 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_131/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 960, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [24, 24] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_76/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m164 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_787 \u001b[36mshape\u001b[0m: [256, 960, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_788 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_131/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 960, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [36, 36] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_77/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m165 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.0/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.0/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_131/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_8/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m166 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_74/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_20/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m167 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_75/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_21/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m168 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_76/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_22/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m169 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_77/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_23/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m170 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.0/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_790 \u001b[36mshape\u001b[0m: [256, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_791 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_8/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_78/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m171 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.3/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_78/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_24/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m172 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.4/Resize\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/classifier/classifier.0/convs.4/Concat_output_0 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_bilinear\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_24/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mshape\u001b[0m: (2,) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: bilinear \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.image.resize_bilinear_1/ResizeBilinear:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m173 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.5\u001b[0m: wa/classifier/classifier.0/convs.4/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 1280, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_20/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_21/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_22/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.input3\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_23/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.input4\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.image.resize_bilinear_1/ResizeBilinear:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat/concat:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m174 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/project/project.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 1280, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_793 \u001b[36mshape\u001b[0m: [256, 1280, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_794 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/project/project.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat/concat:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1280, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_79/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m175 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/project/project.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/project/project.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/project/project.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_79/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_25/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m176 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/project/project.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_796 \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_797 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_25/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_80/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m177 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.3/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_80/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_26/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m178 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.4/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: classifier.4.weight \u001b[36mshape\u001b[0m: [21, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: classifier.4.bias \u001b[36mshape\u001b[0m: [21] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 21, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_26/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (21,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_81/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m179 / 179\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: wa/Resize\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 21, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/Concat_1_output_0 \u001b[36mshape\u001b[0m: (4,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: output \u001b[36mshape\u001b[0m: [1, 21, 300, 300] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_bilinear\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_81/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mshape\u001b[0m: (2,) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: bilinear \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.image.resize_bilinear_2/ResizeBilinear:0 \u001b[34mshape\u001b[0m: (1, 300, 300, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
      "\u001b[32msaved_model output complete!\u001b[0m\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 151, Total Ops 349, % non-converted = 43.27 %\n",
      " * 151 ARITH ops\n",
      "\n",
      "- arith.constant:  151 occurrences  (f32: 146, i32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 30)\n",
      "  (f32: 1)\n",
      "  (f32: 57)\n",
      "  (f32: 15)\n",
      "  (f32: 9)\n",
      "  (f32: 48)\n",
      "  (f32: 4)\n",
      "  (f32: 28)\n",
      "  (f32: 3)\n",
      "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 151, Total Ops 495, % non-converted = 30.51 %\n",
      " * 151 ARITH ops\n",
      "\n",
      "- arith.constant:  151 occurrences  (f16: 146, i32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 30)\n",
      "  (f32: 1)\n",
      "  (f32: 57)\n",
      "  (f32: 15)\n",
      "  (f32: 146)\n",
      "  (f32: 9)\n",
      "  (f32: 48)\n",
      "  (f32: 4)\n",
      "  (f32: 28)\n",
      "  (f32: 3)\n",
      "\u001b[32mFloat16 tflite output complete!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# экспортим модельку в tf\n",
    "!onnx2tf -i dv3_mnv3.onnx -o dv3_mnv3 -osd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad3beb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 21:37:24.791333: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 21:37:24.794679: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 21:37:24.794855: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 21:37:24.795592: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 21:37:24.795665: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 21:37:24.795716: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 21:37:24.884064: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 21:37:24.884159: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 21:37:24.884219: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 21:37:24.884273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14289 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-05-12 21:37:25.521756: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-05-12 21:37:25.521774: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-05-12 21:37:25.522205: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: dv3_mnv3\n",
      "2024-05-12 21:37:25.532415: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-12 21:37:25.532434: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: dv3_mnv3\n",
      "2024-05-12 21:37:25.554714: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-05-12 21:37:25.556420: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-05-12 21:37:25.604874: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: dv3_mnv3\n",
      "2024-05-12 21:37:25.631996: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 109792 microseconds.\n",
      "2024-05-12 21:37:25.697701: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 151, Total Ops 349, % non-converted = 43.27 %\n",
      " * 151 ARITH ops\n",
      "\n",
      "- arith.constant:  151 occurrences  (f32: 146, i32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 30)\n",
      "  (f32: 1)\n",
      "  (f32: 57)\n",
      "  (f32: 15)\n",
      "  (f32: 9)\n",
      "  (f32: 48)\n",
      "  (f32: 4)\n",
      "  (f32: 28)\n",
      "  (f32: 3)\n",
      "2024-05-12 21:37:25.813535: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 6.962 G  ops, equivalently 3.481 G  MACs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44115456"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сохраняем модель в tflite в fp32\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"dv3_mnv3\")\n",
    "tflite_model_quant = converter.convert()\n",
    "Path(\"dv3_mnv3_fp32.tflite\").write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a67f95dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 21:38:01.111959: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-05-12 21:38:01.111980: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-05-12 21:38:01.112100: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: dv3_mnv3\n",
      "2024-05-12 21:38:01.122680: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-12 21:38:01.122699: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: dv3_mnv3\n",
      "2024-05-12 21:38:01.141384: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-05-12 21:38:01.189190: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: dv3_mnv3\n",
      "2024-05-12 21:38:01.216527: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 104427 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 151, Total Ops 495, % non-converted = 30.51 %\n",
      " * 151 ARITH ops\n",
      "\n",
      "- arith.constant:  151 occurrences  (f16: 146, i32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 30)\n",
      "  (f32: 1)\n",
      "  (f32: 57)\n",
      "  (f32: 15)\n",
      "  (f32: 146)\n",
      "  (f32: 9)\n",
      "  (f32: 48)\n",
      "  (f32: 4)\n",
      "  (f32: 28)\n",
      "  (f32: 3)\n",
      "2024-05-12 21:38:01.412167: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 6.962 G  ops, equivalently 3.481 G  MACs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22103636"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сохраняем модель в tflite в fp16\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"dv3_mnv3\")\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_quant = converter.convert()\n",
    "Path(\"dv3_mnv3_fp16.tflite\").write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581714e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 09:55:17.805215: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-05-13 09:55:17.805230: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: gvasserm-desk\n",
      "2024-05-13 09:55:17.805232: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: gvasserm-desk\n",
      "2024-05-13 09:55:17.805288: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 545.29.6\n",
      "2024-05-13 09:55:17.805296: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 545.29.6\n",
      "2024-05-13 09:55:17.805297: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 545.29.6\n",
      "2024-05-13 09:55:18.361717: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-05-13 09:55:18.361741: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-05-13 09:55:18.362072: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: dv3_mnv3\n",
      "2024-05-13 09:55:18.373535: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-13 09:55:18.373552: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: dv3_mnv3\n",
      "2024-05-13 09:55:18.398001: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-05-13 09:55:18.399597: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-05-13 09:55:18.449759: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: dv3_mnv3\n",
      "2024-05-13 09:55:18.478205: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 116133 microseconds.\n",
      "2024-05-13 09:55:18.546274: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 151, Total Ops 349, % non-converted = 43.27 %\n",
      " * 151 ARITH ops\n",
      "\n",
      "- arith.constant:  151 occurrences  (f32: 146, i32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 30)\n",
      "  (f32: 1)\n",
      "  (f32: 57)\n",
      "  (f32: 15)\n",
      "  (f32: 9)\n",
      "  (f32: 48)\n",
      "  (f32: 4)\n",
      "  (f32: 28)\n",
      "  (f32: 3)\n",
      "2024-05-13 09:55:18.666514: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 6.962 G  ops, equivalently 3.481 G  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "2024-05-13 09:56:30.389651: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 6.962 G  ops, equivalently 3.481 G  MACs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11596120"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тут вам нужно сделать dynamic квантование. сохранить модельку с именем \"dv3_mnv3_int8_dynamic.tflite\" (10 баллов)\n",
    "import glob \n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "def representative_dataset():\n",
    "    paths = glob.glob(\"/home/gvasserm/data/coco2017/train2017/*.jpg\")[:200]\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, (300, 300))\n",
    "        img = img[:, :, ::-1]  # Convert BGR to RGB\n",
    "        img = np.expand_dims(img, axis=0).astype(np.float32)\n",
    "        img = (img / 255.0 - mean) / std\n",
    "        yield [img]  # Ensure this is a list of numpy arrays\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"dv3_mnv3\")\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model_quant = converter.convert()\n",
    "Path(\"dv3_mnv3_int8_dynamic.tflite\").write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2af48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ac7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000133b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Начнём замеры!\n",
    "# Для начала проверим есть ли подключённые устройства\n",
    "!adb devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9968cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачаем бенчмарк\n",
    "!wget https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/android_aarch64_benchmark_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# закинем на устройство модельи и бенчмарк\n",
    "!chmod +x android_aarch64_benchmark_model\n",
    "!adb push android_aarch64_benchmark_model /data/local/tmp/\n",
    "!adb push dv3_mnv3_fp32.tflite /data/local/tmp/\n",
    "!adb push dv3_mnv3_fp16.tflite /data/local/tmp/\n",
    "!adb push dv3_mnv3_int8_dynamic.tflite /data/local/tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# запустим модельки в одном потоке на цпу, нужно дождаться вывода времени пример строки:\n",
    "# INFO: Inference timings in us: Init: 55393, First inference: 131849, Warmup (avg): 120734, Inference (avg): 119747\n",
    "!adb shell \"cd /data/local/tmp \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fp32.tflite  --num_threads=1 \\\n",
    "    && echo '-------------------------------------------------' \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fp16.tflite --num_threads=1 \\\n",
    "    && echo '-------------------------------------------------' \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_int8_dynamic.tflite  --num_threads=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# на NNAPI\n",
    "!adb shell \"cd /data/local/tmp \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fp32.tflite  --num_threads=1 --use_nnapi=1 \\\n",
    "    && echo '-------------------------------------------------' \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fp16.tflite --num_threads=1  --use_nnapi=1 \\\n",
    "    && echo '-------------------------------------------------' \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_int8_dynamic.tflite  --num_threads=1  --use_nnapi=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa934e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# и на гпу\n",
    "!adb shell \"cd /data/local/tmp \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fp32.tflite  --num_threads=1 --use_gpu=1 \\\n",
    "    && echo '-------------------------------------------------' \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fp16.tflite --num_threads=1  --use_gpu=1 \\\n",
    "    && echo '-------------------------------------------------' \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_int8_dynamic.tflite  --num_threads=1  --use_gpu=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553568b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В логах мы можем увидеть, что не все операиции операции запустились на GPU и большая часть запустилась \n",
    "# на xnnpack(да и там не все операции запустились),\n",
    "# Время GPU не сильно отличается от CPU. По логам можно понять, что проблема кроется в RELU_0_TO_1. Так же если мы откроем \n",
    "# onnx модельку через netron то мы увидим в ней, активации HardSigmoid и HardSwish. хоть они и поддерживаются в tflite \n",
    "# они не поддерживаются в gpu делегате. https://www.tensorflow.org/lite/performance/gpu\n",
    "# но благо это не такие сложные операции, и от них можно избавится с помощью relu6, умножения и сложенияы, это вам и предстоит сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24143c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь вам предстоит написать код который заменяет операции HardSigmoid (15 баллов) и HardSwish (15 баллов) на эквивалентные.\n",
    "# вы можете сделать это как в torch так и в onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f06609e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepLabV3(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6_Swish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): ReLU6_Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): ReLU6_Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): ReLU6_Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): ReLU6_Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): ReLU6_Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): ReLU6_Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): ReLU6_Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6_Swish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): ReLU6_Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): Conv2dNormActivation(\n",
       "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6_Swish()\n",
       "    )\n",
       "  )\n",
       "  (classifier): DeepLabHead(\n",
       "    (0): ASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ASPPConv(\n",
       "          (0): Conv2d(960, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ASPPConv(\n",
       "          (0): Conv2d(960, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): ASPPConv(\n",
       "          (0): Conv2d(960, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (4): ASPPPooling(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(40, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(10, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ReLU6_Sigmoid(nn.ReLU6):\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return nn.ReLU6().forward(input + 3.)* 0.16666667\n",
    "    \n",
    "class ReLU6_Swish(ReLU6_Sigmoid):\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return input * ReLU6_Sigmoid().forward(input)\n",
    "\n",
    "\n",
    "def convert_hardswish_to_relu6(model):\n",
    "    for child_name, child in model.named_children():\n",
    "        if isinstance(child, nn.Hardswish):\n",
    "            setattr(model, child_name, ReLU6_Swish())\n",
    "        else:\n",
    "            convert_hardswish_to_relu6(child)\n",
    "\n",
    "def convert_hardsigmoid_to_relu6(model):\n",
    "    for child_name, child in model.named_children():\n",
    "        if isinstance(child, nn.Hardsigmoid):\n",
    "            setattr(model, child_name, ReLU6_Sigmoid())\n",
    "        else:\n",
    "            convert_hardsigmoid_to_relu6(child)\n",
    "\n",
    "model_fixed = deeplabv3_mobilenet_v3_large(weights=DeepLabV3_MobileNet_V3_Large_Weights.DEFAULT)\n",
    "convert_hardswish_to_relu6(model_fixed)\n",
    "convert_hardsigmoid_to_relu6(model_fixed)\n",
    "model_fixed.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a63a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраняем и конвертируем модельку\n",
    "input_tensor = torch.rand((1, 3, 300, 300))\n",
    "with torch.no_grad():\n",
    "    output_fixed = model_fixed(input_tensor)['out']\n",
    "\n",
    "torch.onnx.export(model_fixed, input_tensor, f=f\"dv3_mnv3_fixed.onnx\", export_params=True, input_names=['input'], \n",
    "                  do_constant_folding=True, opset_version=13, output_names=['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ee755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add               │ 38             │ 38               │\n",
      "│ Clip              │ 28             │ 28               │\n",
      "│ Concat            │ 4              │ \u001b[1;32m1               \u001b[0m │\n",
      "│ Constant          │ 268            │ \u001b[1;32m150             \u001b[0m │\n",
      "│ Conv              │ 72             │ 72               │\n",
      "│ GlobalAveragePool │ 9              │ 9                │\n",
      "│ Mul               │ 56             │ 56               │\n",
      "│ Relu              │ 27             │ 27               │\n",
      "│ Resize            │ 3              │ 3                │\n",
      "│ Shape             │ 3              │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Slice             │ 3              │ \u001b[1;32m0               \u001b[0m │\n",
      "│ Model Size        │ 42.1MiB        │ \u001b[1;32m42.1MiB         \u001b[0m │\n",
      "└───────────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add               │ 38             │ 38               │\n",
      "│ Clip              │ 28             │ 28               │\n",
      "│ Concat            │ 1              │ 1                │\n",
      "│ Constant          │ 150            │ 150              │\n",
      "│ Conv              │ 72             │ 72               │\n",
      "│ GlobalAveragePool │ 9              │ 9                │\n",
      "│ Mul               │ 56             │ 56               │\n",
      "│ Relu              │ 27             │ 27               │\n",
      "│ Resize            │ 3              │ 3                │\n",
      "│ Model Size        │ 42.1MiB        │ 42.1MiB          │\n",
      "└───────────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│ Add               │ 38             │ 38               │\n",
      "│ Clip              │ 28             │ 28               │\n",
      "│ Concat            │ 1              │ 1                │\n",
      "│ Constant          │ 150            │ 150              │\n",
      "│ Conv              │ 72             │ 72               │\n",
      "│ GlobalAveragePool │ 9              │ 9                │\n",
      "│ Mul               │ 56             │ 56               │\n",
      "│ Relu              │ 27             │ 27               │\n",
      "│ Resize            │ 3              │ 3                │\n",
      "│ Model Size        │ 42.1MiB        │ 42.1MiB          │\n",
      "└───────────────────┴────────────────┴──────────────────┘\n",
      "\n",
      "\u001b[32mModel optimizing complete!\u001b[0m\n",
      "\n",
      "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
      "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
      "\n",
      "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
      "\n",
      "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: input \u001b[32mshape\u001b[0m: [1, 3, 300, 300] \u001b[32mdtype\u001b[0m: float32\n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m2 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.0/backbone.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input \u001b[36mshape\u001b[0m: [1, 3, 300, 300] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_808 \u001b[36mshape\u001b[0m: [16, 3, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_809 \u001b[36mshape\u001b[0m: [16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad/Pad:0 \u001b[34mshape\u001b[0m: (1, 302, 302, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 3, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (16,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m3 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m4 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6/Relu6:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m5 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6/Relu6:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_1/Mul:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m6 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_1/Mul:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_5/Mul:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m7 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_811 \u001b[36mshape\u001b[0m: [16, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_812 \u001b[36mshape\u001b[0m: [16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_5/Mul:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 16, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (16,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 16 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m8 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m9 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.1/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.1/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_814 \u001b[36mshape\u001b[0m: [16, 16, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_815 \u001b[36mshape\u001b[0m: [16] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.1/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 16, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (16,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m10 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.1/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.1/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_5/Mul:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m11 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.1/Add_output_0 \u001b[36mshape\u001b[0m: [1, 16, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_817 \u001b[36mshape\u001b[0m: [64, 16, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_818 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_6/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 16, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m12 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 150, 150, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m13 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.2/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 150, 150] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_820 \u001b[36mshape\u001b[0m: [64, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_821 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_1/Pad:0 \u001b[34mshape\u001b[0m: (1, 152, 152, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 64 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m14 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m15 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.2/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.2/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_823 \u001b[36mshape\u001b[0m: [24, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_824 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.2/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m16 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.2/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_826 \u001b[36mshape\u001b[0m: [72, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_827 \u001b[36mshape\u001b[0m: [72] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (72,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_10/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m17 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_10/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m18 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_829 \u001b[36mshape\u001b[0m: [72, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_830 \u001b[36mshape\u001b[0m: [72] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 72, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (72,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 72 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m19 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_11/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m20 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_832 \u001b[36mshape\u001b[0m: [24, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_833 \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 72, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m21 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.3/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.2/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.3/Add_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_12/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m22 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.3/Add_output_0 \u001b[36mshape\u001b[0m: [1, 24, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_835 \u001b[36mshape\u001b[0m: [72, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_836 \u001b[36mshape\u001b[0m: [72] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (72,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m23 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_5/Relu:0 \u001b[34mshape\u001b[0m: (1, 75, 75, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m24 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 75, 75] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_838 \u001b[36mshape\u001b[0m: [72, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_839 \u001b[36mshape\u001b[0m: [72] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_2/Pad:0 \u001b[34mshape\u001b[0m: (1, 79, 79, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 72, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (72,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 72 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m25 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m26 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m27 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.4.block.2.fc1.weight \u001b[36mshape\u001b[0m: [24, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.4.block.2.fc1.bias \u001b[36mshape\u001b[0m: [24] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 72, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (24,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m28 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_17/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m29 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.4.block.2.fc2.weight \u001b[36mshape\u001b[0m: [72, 24, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.4.block.2.fc2.bias \u001b[36mshape\u001b[0m: [72] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 24) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 24, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (72,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m30 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_18/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m31 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_1/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m32 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_1/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_10/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m33 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.4/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_10/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_14/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m34 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.4/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 72, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_841 \u001b[36mshape\u001b[0m: [40, 72, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_842 \u001b[36mshape\u001b[0m: [40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.4/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_14/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 72) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 72, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (40,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m35 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_844 \u001b[36mshape\u001b[0m: [120, 40, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_845 \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 40, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m36 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/aux_classifier/aux_classifier.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.4/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_967 \u001b[36mshape\u001b[0m: [10, 40, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_968 \u001b[36mshape\u001b[0m: [10] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/aux_classifier/aux_classifier.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 10, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 40, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (10,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m37 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m38 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/aux_classifier/aux_classifier.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/aux_classifier/aux_classifier.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 10, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/aux_classifier/aux_classifier.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 10, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m39 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_847 \u001b[36mshape\u001b[0m: [120, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_848 \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 120, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 120 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m40 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/aux_classifier/aux_classifier.4/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/aux_classifier/aux_classifier.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 10, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: aux_classifier.4.weight \u001b[36mshape\u001b[0m: [21, 10, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: aux_classifier.4.bias \u001b[36mshape\u001b[0m: [21] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/aux_classifier/aux_classifier.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 21, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 10) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 10, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (21,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_24/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m41 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m42 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: wa/Resize_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/aux_classifier/aux_classifier.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 21, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/Concat_output_0 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: 806 \u001b[36mshape\u001b[0m: [1, 21, 300, 300] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_bilinear\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_24/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mshape\u001b[0m: (2,) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: bilinear \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.image.resize_bilinear/ResizeBilinear:0 \u001b[34mshape\u001b[0m: (1, 300, 300, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m43 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_1/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m44 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.5.block.2.fc1.weight \u001b[36mshape\u001b[0m: [32, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.5.block.2.fc1.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_1/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 120, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m45 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_25/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m46 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.5.block.2.fc2.weight \u001b[36mshape\u001b[0m: [120, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.5.block.2.fc2.bias \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m47 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m48 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_2/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m49 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_2/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_15/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m50 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.5/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_15/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_19/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m51 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_850 \u001b[36mshape\u001b[0m: [40, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_851 \u001b[36mshape\u001b[0m: [40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_19/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 120, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (40,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_28/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m52 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.5/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.4/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.5/Add_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_28/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m53 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.5/Add_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_853 \u001b[36mshape\u001b[0m: [120, 40, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_854 \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 40, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m54 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_31/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_12/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m55 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.0/block.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_856 \u001b[36mshape\u001b[0m: [120, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_857 \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_12/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 120, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 120 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m56 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m57 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_2/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m58 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.6.block.2.fc1.weight \u001b[36mshape\u001b[0m: [32, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.6.block.2.fc1.bias \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_2/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 120, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m59 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m60 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.6.block.2.fc2.weight \u001b[36mshape\u001b[0m: [120, 32, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.6.block.2.fc2.bias \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 32, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m61 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_35/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m62 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_35/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_3/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m63 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_3/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_22/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m64 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.6/block/block.1/block.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_22/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_26/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m65 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 120, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_859 \u001b[36mshape\u001b[0m: [40, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_860 \u001b[36mshape\u001b[0m: [40] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_26/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 120, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (40,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_36/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m66 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.6/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.5/Add_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.6/Add_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_36/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_30/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m67 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.6/Add_output_0 \u001b[36mshape\u001b[0m: [1, 40, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_862 \u001b[36mshape\u001b[0m: [240, 40, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_863 \u001b[36mshape\u001b[0m: [240] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 40) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 40, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (240,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_39/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m68 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_39/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m69 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_4/Relu6:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m70 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_4/Relu6:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_30/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m71 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_39/Add:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_30/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_34/Mul:0 \u001b[34mshape\u001b[0m: (1, 38, 38, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m72 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 240, 38, 38] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_865 \u001b[36mshape\u001b[0m: [240, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_866 \u001b[36mshape\u001b[0m: [240] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_3/Pad:0 \u001b[34mshape\u001b[0m: (1, 40, 40, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 240, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (240,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 2, 2, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 240 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m73 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m74 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_5/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m75 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_5/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_36/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m76 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_42/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_36/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_40/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m77 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.7/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 240, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_868 \u001b[36mshape\u001b[0m: [80, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_869 \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.7/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_40/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 240, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m78 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.7/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_871 \u001b[36mshape\u001b[0m: [200, 80, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_872 \u001b[36mshape\u001b[0m: [200] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 80, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (200,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m79 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m80 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_6/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m81 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_6/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_42/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m82 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_42/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_46/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m83 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_874 \u001b[36mshape\u001b[0m: [200, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_875 \u001b[36mshape\u001b[0m: [200] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_46/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 200, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (200,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 200 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m84 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_51/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m85 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_51/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_7/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m86 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_7/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_48/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m87 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_49/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_48/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_52/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m88 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 200, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_877 \u001b[36mshape\u001b[0m: [80, 200, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_878 \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_52/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 200) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 200, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m89 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.8/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.7/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.8/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m90 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.8/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_880 \u001b[36mshape\u001b[0m: [184, 80, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_881 \u001b[36mshape\u001b[0m: [184] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 80, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (184,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_55/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m91 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_55/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m92 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_8/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m93 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_8/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_56/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m94 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_55/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_56/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_60/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m95 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_883 \u001b[36mshape\u001b[0m: [184, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_884 \u001b[36mshape\u001b[0m: [184] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_60/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 184, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (184,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 184 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m96 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m97 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_9/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m98 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_9/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_62/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m99 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_62/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_66/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m100 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_886 \u001b[36mshape\u001b[0m: [80, 184, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_887 \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_66/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 184, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_61/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m101 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.9/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.8/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.9/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_61/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_63/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m102 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.9/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_889 \u001b[36mshape\u001b[0m: [184, 80, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_890 \u001b[36mshape\u001b[0m: [184] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_63/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 80, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (184,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_64/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m103 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_64/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_66/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m104 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_66/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_10/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m105 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_10/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_70/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m106 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_64/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_70/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_74/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m107 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_892 \u001b[36mshape\u001b[0m: [184, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_893 \u001b[36mshape\u001b[0m: [184] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_74/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 184, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (184,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 184 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_67/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m108 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_67/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_69/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m109 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_69/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_11/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m110 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_11/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_76/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m111 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_67/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_76/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_80/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m112 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/block/block.2/block.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 184, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_895 \u001b[36mshape\u001b[0m: [80, 184, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_896 \u001b[36mshape\u001b[0m: [80] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_80/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 184) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 184, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (80,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_70/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m113 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.10/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/block/block.2/block.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.9/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.10/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_70/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_63/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_72/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m114 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.10/Add_output_0 \u001b[36mshape\u001b[0m: [1, 80, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_898 \u001b[36mshape\u001b[0m: [480, 80, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_899 \u001b[36mshape\u001b[0m: [480] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_72/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 80) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 80, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (480,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_73/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m115 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_73/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_75/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m116 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_75/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_12/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m117 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_12/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_84/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m118 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_73/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_84/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_88/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m119 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_901 \u001b[36mshape\u001b[0m: [480, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_902 \u001b[36mshape\u001b[0m: [480] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_88/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 480, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (480,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 480 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_76/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m120 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_76/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_78/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m121 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_78/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_13/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m122 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_13/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_90/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m123 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_76/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_90/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_94/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m124 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_94/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_3/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m125 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.11.block.2.fc1.weight \u001b[36mshape\u001b[0m: [120, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.11.block.2.fc1.bias \u001b[36mshape\u001b[0m: [120] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_3/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 480, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (120,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_79/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m126 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_79/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_15/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m127 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.11.block.2.fc2.weight \u001b[36mshape\u001b[0m: [480, 120, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.11.block.2.fc2.bias \u001b[36mshape\u001b[0m: [480] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_15/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 120) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 120, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (480,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_80/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m128 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_80/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_81/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m129 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_81/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_14/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m130 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_14/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_95/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m131 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.11/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_95/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_94/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_99/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m132 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.11/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 480, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_904 \u001b[36mshape\u001b[0m: [112, 480, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_905 \u001b[36mshape\u001b[0m: [112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.11/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_99/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 480) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 480, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (112,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_82/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m133 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.11/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_907 \u001b[36mshape\u001b[0m: [672, 112, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_908 \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_82/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 112, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_83/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m134 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_83/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_85/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m135 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_85/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_15/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m136 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_15/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_101/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m137 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_83/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_101/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_105/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m138 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_910 \u001b[36mshape\u001b[0m: [672, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_911 \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_105/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 672, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 672 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_86/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m139 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_86/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_88/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m140 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_88/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_16/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m141 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_16/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_107/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m142 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_86/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_107/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_111/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m143 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_111/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_4/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m144 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.12.block.2.fc1.weight \u001b[36mshape\u001b[0m: [168, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.12.block.2.fc1.bias \u001b[36mshape\u001b[0m: [168] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_4/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 672, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (168,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_89/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m145 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_89/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m146 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.12.block.2.fc2.weight \u001b[36mshape\u001b[0m: [672, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.12.block.2.fc2.bias \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 168, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_90/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m147 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_90/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_91/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m148 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_91/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_17/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m149 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_17/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_112/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m150 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.12/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_112/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_111/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_116/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m151 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_913 \u001b[36mshape\u001b[0m: [112, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_914 \u001b[36mshape\u001b[0m: [112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_116/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 672, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (112,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_92/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m152 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.12/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.11/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.12/Add_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_92/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_82/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_94/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m153 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.12/Add_output_0 \u001b[36mshape\u001b[0m: [1, 112, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_916 \u001b[36mshape\u001b[0m: [672, 112, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_917 \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_94/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 112) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 112, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_95/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m154 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_95/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_97/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m155 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_97/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_18/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m156 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_18/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_120/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m157 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_95/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_120/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_124/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m158 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_919 \u001b[36mshape\u001b[0m: [672, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_920 \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_124/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 672, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 672 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_98/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m159 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_98/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_100/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m160 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_100/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_19/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m161 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_19/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_126/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m162 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_98/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_126/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_130/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m163 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_130/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_5/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m164 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.13.block.2.fc1.weight \u001b[36mshape\u001b[0m: [168, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.13.block.2.fc1.bias \u001b[36mshape\u001b[0m: [168] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_5/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 672, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (168,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_101/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m165 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_101/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m166 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.13.block.2.fc2.weight \u001b[36mshape\u001b[0m: [672, 168, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.13.block.2.fc2.bias \u001b[36mshape\u001b[0m: [672] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 168) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 168, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (672,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_102/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m167 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_102/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_103/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m168 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_103/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_20/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m169 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_20/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_131/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m170 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.13/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_131/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_130/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_135/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m171 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.13/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 672, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_922 \u001b[36mshape\u001b[0m: [160, 672, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_923 \u001b[36mshape\u001b[0m: [160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.13/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_135/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 672) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 672, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (160,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_104/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m172 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.13/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_925 \u001b[36mshape\u001b[0m: [960, 160, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_926 \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_104/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 160, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_105/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m173 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_105/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_107/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m174 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_107/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_21/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m175 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_21/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_137/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m176 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_105/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_137/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_141/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m177 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_928 \u001b[36mshape\u001b[0m: [960, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_929 \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_141/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 960, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 960 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_108/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m178 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_108/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_110/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m179 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_110/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_22/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m180 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_22/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_143/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m181 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_108/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_143/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_147/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m182 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_147/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_6/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m183 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.14.block.2.fc1.weight \u001b[36mshape\u001b[0m: [240, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.14.block.2.fc1.bias \u001b[36mshape\u001b[0m: [240] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_6/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (240,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_111/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m184 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_111/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_18/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m185 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.14.block.2.fc2.weight \u001b[36mshape\u001b[0m: [960, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.14.block.2.fc2.bias \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_18/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 240, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_112/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m186 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_112/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_113/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m187 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_113/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_23/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m188 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_23/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_148/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m189 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.14/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_148/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_147/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_152/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m190 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_931 \u001b[36mshape\u001b[0m: [160, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_932 \u001b[36mshape\u001b[0m: [160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_152/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (160,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_114/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m191 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.14/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.13/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.14/Add_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_114/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_104/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_116/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m192 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.14/Add_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_934 \u001b[36mshape\u001b[0m: [960, 160, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_935 \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_116/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 160, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_117/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m193 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_117/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_119/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m194 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_119/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_24/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m195 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_24/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_156/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m196 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_117/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_156/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_160/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m197 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.0/block.0.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_937 \u001b[36mshape\u001b[0m: [960, 1, 5, 5] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_938 \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: depthwise_conv2d_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_160/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 5, 960, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 960 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_120/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m198 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_120/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_122/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m199 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_122/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_25/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m200 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_25/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_162/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m201 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_120/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_162/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_166/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m202 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/avgpool/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_166/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_7/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m203 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/fc1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/avgpool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.15.block.2.fc1.weight \u001b[36mshape\u001b[0m: [240, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.15.block.2.fc1.bias \u001b[36mshape\u001b[0m: [240] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_7/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (240,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_123/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m204 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/activation/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/fc1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_123/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_19/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m205 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/fc2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/activation/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: backbone.15.block.2.fc2.weight \u001b[36mshape\u001b[0m: [960, 240, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: backbone.15.block.2.fc2.bias \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_19/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 240) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 240, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_124/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m206 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/fc2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_124/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_125/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m207 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_125/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_26/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m208 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_26/Relu6:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_167/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m209 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/scale_activation/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.15/block/block.1/block.1.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_167/Mul:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_166/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_171/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m210 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/block/block.3/block.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_940 \u001b[36mshape\u001b[0m: [160, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_941 \u001b[36mshape\u001b[0m: [160] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_171/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (160,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_126/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m211 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.15/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/block/block.3/block.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.14/Add_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.15/Add_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_126/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_116/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_128/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m212 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.16/backbone.16.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.15/Add_output_0 \u001b[36mshape\u001b[0m: [1, 160, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_943 \u001b[36mshape\u001b[0m: [960, 160, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_944 \u001b[36mshape\u001b[0m: [960] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_128/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 160) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 160, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (960,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_129/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m213 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_129/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_131/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m214 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Clip\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Add_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_1_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_2_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu6\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_131/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_27/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m215 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Clip_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.0/backbone.0.2/Constant_3_output_0 \u001b[36mshape\u001b[0m: () \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu6_27/Relu6:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_175/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m216 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_1\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_129/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_175/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_179/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m217 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_946 \u001b[36mshape\u001b[0m: [256, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_947 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_179/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_132/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m218 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_949 \u001b[36mshape\u001b[0m: [256, 960, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_950 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_179/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 960, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [12, 12] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_133/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m219 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_952 \u001b[36mshape\u001b[0m: [256, 960, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_953 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_179/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 960, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [24, 24] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_134/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m220 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_955 \u001b[36mshape\u001b[0m: [256, 960, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_956 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_179/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 960, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [36, 36] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_135/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m221 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.0/GlobalAveragePool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/backbone/backbone.16/backbone.16.2/Mul_1_output_0 \u001b[36mshape\u001b[0m: [1, 960, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.0/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_179/Mul:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_8/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m222 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_132/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_20/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m223 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_133/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_21/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m224 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_134/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_22/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m225 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_135/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_23/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m226 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.0/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: [1, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_958 \u001b[36mshape\u001b[0m: [256, 960, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_959 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_8/Mean:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 960) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 960, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_136/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m227 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.3/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_136/Add:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_24/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m228 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/convs.4/Resize\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/convs.4.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/classifier/classifier.0/convs.4/Concat_output_0 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/convs.4/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_bilinear\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_24/Relu:0 \u001b[34mshape\u001b[0m: (1, 1, 1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mshape\u001b[0m: (2,) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: bilinear \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.image.resize_bilinear_1/ResizeBilinear:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m229 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/Concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/convs.0/convs.0.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: wa/classifier/classifier.0/convs.1/convs.1.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: wa/classifier/classifier.0/convs.2/convs.2.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/classifier/classifier.0/convs.3/convs.3.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.5\u001b[0m: wa/classifier/classifier.0/convs.4/Resize_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 1280, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_20/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_21/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.input2\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_22/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.input3\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_23/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.input4\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.image.resize_bilinear_1/ResizeBilinear:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.axis\u001b[0m: \u001b[34mval\u001b[0m: 3 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat/concat:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m230 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/project/project.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/Concat_output_0 \u001b[36mshape\u001b[0m: [1, 1280, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_961 \u001b[36mshape\u001b[0m: [256, 1280, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_962 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/project/project.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.concat/concat:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 1280) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1280, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_137/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m231 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.0/project/project.2/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/project/project.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.0/project/project.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_137/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_25/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m232 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.1/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.0/project/project.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_964 \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_965 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_25/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_138/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m233 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.3/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_138/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_26/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m234 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: wa/classifier/classifier.4/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: classifier.4.weight \u001b[36mshape\u001b[0m: [21, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: classifier.4.bias \u001b[36mshape\u001b[0m: [21] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: wa/classifier/classifier.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 21, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_26/Relu:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (21,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_139/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m235 / 235\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Resize\u001b[35m onnx_op_name\u001b[0m: wa/Resize\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: wa/classifier/classifier.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 21, 19, 19] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: wa/Concat_output_0 \u001b[36mshape\u001b[0m: (4,) \u001b[36mdtype\u001b[0m: int64\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: output \u001b[36mshape\u001b[0m: [1, 21, 300, 300] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: upsampling2d_bilinear\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.images\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_139/Add:0 \u001b[34mshape\u001b[0m: (1, 19, 19, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.boxes\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.box_indices\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.new_size/crop_size\u001b[0m: \u001b[34mshape\u001b[0m: (2,) \u001b[34mdtype\u001b[0m: <dtype: 'int32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.method\u001b[0m: \u001b[34mval\u001b[0m: bilinear \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.extrapolation_value\u001b[0m: \u001b[34mval\u001b[0m: 0.0 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.align_corners\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.image.resize_bilinear_2/ResizeBilinear:0 \u001b[34mshape\u001b[0m: (1, 300, 300, 21) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
      "\u001b[32msaved_model output complete!\u001b[0m\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 151, Total Ops 329, % non-converted = 45.90 %\n",
      " * 151 ARITH ops\n",
      "\n",
      "- arith.constant:  151 occurrences  (f32: 146, i32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 30)\n",
      "  (f32: 1)\n",
      "  (f32: 57)\n",
      "  (f32: 15)\n",
      "  (f32: 9)\n",
      "  (f32: 56)\n",
      "  (f32: 4)\n",
      "  (f32: 3)\n",
      "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 151, Total Ops 475, % non-converted = 31.79 %\n",
      " * 151 ARITH ops\n",
      "\n",
      "- arith.constant:  151 occurrences  (f16: 146, i32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 30)\n",
      "  (f32: 1)\n",
      "  (f32: 57)\n",
      "  (f32: 15)\n",
      "  (f32: 146)\n",
      "  (f32: 9)\n",
      "  (f32: 56)\n",
      "  (f32: 4)\n",
      "  (f32: 3)\n",
      "\u001b[32mFloat16 tflite output complete!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!onnx2tf -i dv3_mnv3_fixed.onnx -o dv3_mnv3_fixed -osd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95335718",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_SAVED_MODEL_DIR = \"dv3_mnv3_fixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73952c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 11:31:54.906294: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-05-13 11:31:54.906311: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: gvasserm-desk\n",
      "2024-05-13 11:31:54.906314: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: gvasserm-desk\n",
      "2024-05-13 11:31:54.906341: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 545.29.6\n",
      "2024-05-13 11:31:54.906348: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 545.29.6\n",
      "2024-05-13 11:31:54.906350: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 545.29.6\n",
      "2024-05-13 11:31:55.437287: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-05-13 11:31:55.437310: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-05-13 11:31:55.437682: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: dv3_mnv3_fixed\n",
      "2024-05-13 11:31:55.447680: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-13 11:31:55.447697: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: dv3_mnv3_fixed\n",
      "2024-05-13 11:31:55.467705: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-05-13 11:31:55.469161: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-05-13 11:31:55.515144: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: dv3_mnv3_fixed\n",
      "2024-05-13 11:31:55.538683: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 101001 microseconds.\n",
      "2024-05-13 11:31:55.602506: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 151, Total Ops 329, % non-converted = 45.90 %\n",
      " * 151 ARITH ops\n",
      "\n",
      "- arith.constant:  151 occurrences  (f32: 146, i32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 30)\n",
      "  (f32: 1)\n",
      "  (f32: 57)\n",
      "  (f32: 15)\n",
      "  (f32: 9)\n",
      "  (f32: 56)\n",
      "  (f32: 4)\n",
      "  (f32: 3)\n",
      "2024-05-13 11:31:55.705917: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 6.962 G  ops, equivalently 3.481 G  MACs\n",
      "2024-05-13 11:31:56.699965: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-05-13 11:31:56.699988: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-05-13 11:31:56.700157: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: dv3_mnv3_fixed\n",
      "2024-05-13 11:31:56.709752: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-13 11:31:56.709771: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: dv3_mnv3_fixed\n",
      "2024-05-13 11:31:56.727899: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-05-13 11:31:56.775046: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: dv3_mnv3_fixed\n",
      "2024-05-13 11:31:56.802719: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 102563 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 151, Total Ops 475, % non-converted = 31.79 %\n",
      " * 151 ARITH ops\n",
      "\n",
      "- arith.constant:  151 occurrences  (f16: 146, i32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 30)\n",
      "  (f32: 1)\n",
      "  (f32: 57)\n",
      "  (f32: 15)\n",
      "  (f32: 146)\n",
      "  (f32: 9)\n",
      "  (f32: 56)\n",
      "  (f32: 4)\n",
      "  (f32: 3)\n",
      "2024-05-13 11:31:57.009746: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 6.962 G  ops, equivalently 3.481 G  MACs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22100084"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сохраняем модель в tflite в fp32\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(FIXED_SAVED_MODEL_DIR)\n",
    "tflite_model_quant = converter.convert()\n",
    "Path(\"dv3_mnv3_fixed_fp32.tflite\").write_bytes(tflite_model_quant)\n",
    "\n",
    "# сохраняем модель в tflite в fp16\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(FIXED_SAVED_MODEL_DIR)\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_quant = converter.convert()\n",
    "Path(\"dv3_mnv3_fixed_fp16.tflite\").write_bytes(tflite_model_quant)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d24d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 11:34:18.840101: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-05-13 11:34:18.840121: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-05-13 11:34:18.840242: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: dv3_mnv3_fixed\n",
      "2024-05-13 11:34:18.851023: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-13 11:34:18.851039: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: dv3_mnv3_fixed\n",
      "2024-05-13 11:34:18.875835: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-05-13 11:34:18.925472: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: dv3_mnv3_fixed\n",
      "2024-05-13 11:34:18.954232: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 113989 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 151, Total Ops 329, % non-converted = 45.90 %\n",
      " * 151 ARITH ops\n",
      "\n",
      "- arith.constant:  151 occurrences  (f32: 146, i32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 30)\n",
      "  (f32: 1)\n",
      "  (f32: 57)\n",
      "  (f32: 15)\n",
      "  (f32: 9)\n",
      "  (f32: 56)\n",
      "  (f32: 4)\n",
      "  (f32: 3)\n",
      "2024-05-13 11:34:19.139211: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 6.962 G  ops, equivalently 3.481 G  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n",
      "2024-05-13 11:35:25.390719: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 6.962 G  ops, equivalently 3.481 G  MACs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11591768"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# здесь нужно сделать dynamic квантование пофикшеной модели (10 баллов)\n",
    "import glob \n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "def representative_dataset():\n",
    "    paths = glob.glob(\"/home/gvasserm/data/coco2017/train2017/*.jpg\")[:200]\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, (300, 300))\n",
    "        img = img[:, :, ::-1]  # Convert BGR to RGB\n",
    "        img = np.expand_dims(img, axis=0).astype(np.float32)\n",
    "        img = (img / 255.0 - mean) / std\n",
    "        yield [img]  # Ensure this is a list of numpy arrays\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(FIXED_SAVED_MODEL_DIR)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model_quant = converter.convert()\n",
    "Path(\"dv3_mnv3_fixed_int8.tflite\").write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95925e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce49c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!adb push dv3_mnv3_fixed_fp32.tflite /data/local/tmp/\n",
    "!adb push dv3_mnv3_fixed_fp16.tflite /data/local/tmp/\n",
    "!adb push dv3_mnv3_fixed_int8_dynamic.tflite /data/local/tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d9486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!adb shell \"cd /data/local/tmp \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fixed_fp32.tflite  --num_threads=1 --use_gpu=1 \\\n",
    "    && echo '-------------------------------------------------' \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fixed_fp16.tflite --num_threads=1  --use_gpu=1 \\\n",
    "    && echo '-------------------------------------------------' \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fixed_int8_dynamic.tflite  --num_threads=1  --use_gpu=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a90d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно увидеть что все ноды сконвертились и моделька стала работать куда быстрее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe94408",
   "metadata": {},
   "outputs": [],
   "source": [
    "!adb shell \"cd /data/local/tmp \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fixed_fp32.tflite  --num_threads=1 --use_nnapi=1 \\\n",
    "    && echo '-------------------------------------------------' \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fixed_fp16.tflite --num_threads=1  --use_nnapi=1 \\\n",
    "    && echo '-------------------------------------------------' \\\n",
    "    && ./android_aarch64_benchmark_model --graph=dv3_mnv3_fixed_int8_dynamic.tflite  --num_threads=1  --use_nnapi=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1335ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Тоже самое можно увидеть и на других делегатах"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
