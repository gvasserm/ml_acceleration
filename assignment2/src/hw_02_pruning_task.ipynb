{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSniQYqnwccX"
   },
   "source": [
    "# ÐŸÑ€ÑƒÐ½Ð¸Ð½Ð³ [SegFormer](https://huggingface.co/docs/transformers/model_doc/segformer) (50 Ð±Ð°Ð»Ð»Ð¾Ð²)\n",
    "\n",
    "Ð‘ÑƒÐ´ÐµÐ¼ Ð¿Ñ€ÑƒÐ½Ð¸Ñ‚ÑŒ [SegFormer](https://huggingface.co/docs/transformers/model_doc/segformer) Ð´Ð»Ñ [Ð·Ð°Ð´Ð°Ñ‡Ð¸ ÑÐµÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ Ð»ÑŽÐ´ÐµÐ¹](https://www.kaggle.com/datasets/laurentmih/aisegmentcom-matting-human-datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vdpE2jBwfLT"
   },
   "source": [
    "## Ð¡ÐºÐ°Ñ‡Ð°ÐµÐ¼ Ð²ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð´ Ð¸ Ñ‡ÐµÐºÐ¿Ð¾Ð¸Ð½Ñ‚ Ð±ÐµÐ¹Ð·Ð»Ð°Ð¹Ð½Ð° (Ð½Ðµ Ñ‚Ð¾ Ð¶Ðµ, Ñ‡Ñ‚Ð¾ Ð² Ð¿ÐµÑ€Ð²Ð¾Ð¹ Ð´Ð¾Ð¼Ð°ÑˆÐºÐµ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVaGtWUgwnpZ",
    "outputId": "f53d3412-a857-47c3-b611-6a5e9d329a0a"
   },
   "outputs": [],
   "source": [
    "# !wget -O hw_files_2.zip 'https://www.dropbox.com/scl/fi/66vn2n3p2nb1tjzs2jmog/hw_files_2.zip?rlkey=0je4fwxakn3zb3mqsewhkdjc8&dl=0'\n",
    "# !unzip hw_files_2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDj8ZApIDnVJ"
   },
   "source": [
    "### Ð¡ÐºÐ°Ñ‡Ð°ÐµÐ¼ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚ (Ð•ÑÐ»Ð¸ Ð¾ÑÑ‚Ð°Ð»ÑÑ Ñ 1Ð¾Ð¹ Ð´Ð¾Ð¼ÑˆÐºÐ¸ Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿ÐµÑ€ÐµÐ¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "id": "vKqsIoAaDsyg",
    "outputId": "26b7a13d-736d-403e-ab0e-abf08148e24f"
   },
   "outputs": [],
   "source": [
    "# https://drive.google.com/file/d/1YOEDzZvhLb2DS1Yn7p7MSs41ou3ZBXUq/view?usp=sharing\n",
    "# !unzip matting_human_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDR-qEWJwccb"
   },
   "source": [
    "### Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ð¼ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð­Ñ‚Ð¸ Ð¸Ð· Ð¿Ñ€Ð¾ÑˆÐ»Ð¾Ð¹ Ð´Ð¾Ð¼Ð°ÑˆÐºÐ¸:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OwdgHUS1wccb",
    "outputId": "0b396f3e-4628-4d77-eba4-f00fd5909e08"
   },
   "outputs": [],
   "source": [
    "!pip install torch transformers datasets tensorboard pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð ÑÑ‚Ð¸ Ð½Ð¾Ð²Ñ‹Ðµ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch_pruning\n",
      "  Downloading torch_pruning-1.3.7-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 KB\u001b[0m \u001b[31m627.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/gvasserm/.local/lib/python3.10/site-packages (from torch_pruning) (1.26.4)\n",
      "Requirement already satisfied: torch in /home/gvasserm/.local/lib/python3.10/site-packages (from torch_pruning) (2.2.1+cu121)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (4.9.0)\n",
      "Requirement already satisfied: filelock in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (2.19.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (12.1.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (8.9.2.26)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (11.4.5.107)\n",
      "Requirement already satisfied: networkx in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (10.3.2.106)\n",
      "Requirement already satisfied: fsspec in /home/gvasserm/.local/lib/python3.10/site-packages (from torch->torch_pruning) (2024.2.0)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch->torch_pruning) (1.9)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/gvasserm/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torch_pruning) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gvasserm/.local/lib/python3.10/site-packages (from jinja2->torch->torch_pruning) (2.1.5)\n",
      "Installing collected packages: torch_pruning\n",
      "Successfully installed torch_pruning-1.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QjHHo_eLpYMa"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Calculate the absolute path to the parent directory (two levels up)\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "# Convert the Path object to a string and add it to sys.path\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "\n",
    "import typing\n",
    "import torch\n",
    "\n",
    "from copy import deepcopy\n",
    "from datasets import load_metric\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# utils Ñƒ Ð½Ð°Ñ Ð¿Ð¾ÑÐ²Ð¸Ð»Ð¸ÑÑŒ Ð¿Ñ€Ð¸ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ð¸ Ð²ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ ÐºÐ¾Ð´Ð°. ÐŸÑ€Ð¸ Ð¶ÐµÐ»Ð°Ð½Ð¸Ð¸ Ð¼Ð¾Ð¶Ð½Ð¾ Ð² Ð½Ð¸Ñ… Ð¿Ñ€Ð¾Ð²Ð°Ð»Ð¸Ñ‚ÑŒÑÑ-Ð¿Ð¾Ð¸Ð·ÑƒÑ‡Ð°Ñ‚ÑŒ\n",
    "from utils.data import init_dataloaders\n",
    "from utils.model import evaluate_model\n",
    "from utils.model import init_model_with_pretrain, init_model_student_with_pretrain\n",
    "\n",
    "from torch import nn\n",
    "from transformers.models.segformer.modeling_segformer import SegformerLayer, SegformerEfficientSelfAttention\n",
    "\n",
    "import torch_pruning as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aXKfFbGmwccf"
   },
   "outputs": [],
   "source": [
    "distilled_ckpt = '../../assignment1/runs/distillation/ckpt_6.pth'\n",
    "save_dir = '../../assignment2/runs/magnitude_equal_pruning'\n",
    "baseline_path = \"../../assignment2/runs/baseline_ckpt.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "B8GpVF2Dpkvs"
   },
   "outputs": [],
   "source": [
    "# Ð¼Ð°Ð¿Ð¿Ð¸Ð½Ð³ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ ÐºÐ»Ð°ÑÑÐ¾Ð² Ð¸ Ð¸Ð½Ð´ÐµÐºÑÐ¾Ð²\n",
    "id2label = {\n",
    "    0: \"background\",\n",
    "    1: \"human\",\n",
    "}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5H4Q1OK282K"
   },
   "source": [
    "Ð¡Ð¾Ð·Ð´Ð°Ð´Ð¸Ð¼ Ð»Ð¾Ð°Ð´ÐµÑ€Ñ‹:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DezHZJUSqIL_",
    "outputId": "909eb073-0ccf-4f29-8d7c-2076119ec480"
   },
   "outputs": [],
   "source": [
    "dataset_dir = \"/home/gvasserm/data/matting_human_dataset/\"\n",
    "train_dataloader, valid_dataloader = init_dataloaders(\n",
    "    root_dir=dataset_dir,\n",
    "    batch_size=8,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVu73sbywccj"
   },
   "source": [
    "Ð¡Ð¾Ð·Ð´Ð°Ð´Ð¸Ð¼ baseline Ð¼Ð¾Ð´ÐµÐ»ÑŒ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9cYusOhwcck",
    "outputId": "984e0cb8-92da-4324-9681-25bc661d0e0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_fuse.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "baseline_model = init_model_with_pretrain(label2id=label2id, id2label=id2label, pretrain_path=baseline_path).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruBhMcBYwccl"
   },
   "source": [
    "Ð˜ ÑÑ€Ð°Ð·Ñƒ Ð¾Ñ‚Ð²Ð°Ð»Ð¸Ð´Ð¸Ñ€ÑƒÐµÐ¼:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBFZ4REuwccl",
    "outputId": "9f78796d-4c91-41cd-ad27-e63eb3e52f06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gvasserm/dev/ml_acceleration/utils/model.py:38: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  state_dict = torch.load(pretrain_path, devices)['state_dict']\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.9825463313870122\n",
      "Mean accuracy: 0.9910212045247916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_iou': 0.9825463313870122,\n",
       " 'mean_accuracy': 0.9910212045247916,\n",
       " 'overall_accuracy': 0.9912375183105469,\n",
       " 'per_category_iou': array([0.98135781, 0.98373485]),\n",
       " 'per_category_accuracy': array([0.98774413, 0.99429828])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(baseline_model, valid_dataloader, id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð¡Ð¾Ð·Ð´Ð°Ð´Ð¸Ð¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ð¾ÑÐ»Ðµ Ð´Ð¸ÑÑ‚Ð¸Ð»Ð»ÑÑ†Ð¸Ð¸ (Ð¼Ð¾Ð¶Ð½Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ,Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð½ÑƒÑŽ Ð² Ð¿ÐµÑ€Ð²Ð¾Ð¹ Ð´Ð¾Ð¼Ð°ÑˆÐºÐµ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilled_model = init_model_student_with_pretrain(distilled_ckpt).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ð¼ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.9646906777392876\n",
      "Mean accuracy: 0.9816622249066476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_iou': 0.9646906777392876,\n",
       " 'mean_accuracy': 0.9816622249066476,\n",
       " 'overall_accuracy': 0.9821188583374023,\n",
       " 'per_category_iou': array([0.96220293, 0.96717842]),\n",
       " 'per_category_accuracy': array([0.97474439, 0.98858006])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(distilled_model, valid_dataloader, id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÐžÑ†ÐµÐ½Ð¸Ð¼ Ð²Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¸ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_example = torch.rand(1,3,512,512, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model complexity: 6761.228288 MMAC, 3.714658 M params\n"
     ]
    }
   ],
   "source": [
    "ops, params = tp.utils.count_ops_and_params(baseline_model, input_example)\n",
    "print(f\"Baseline model complexity: {ops/1e6} MMAC, {params/1e6} M params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled model complexity: 5841.819136 MMAC, 2.29821 M params\n"
     ]
    }
   ],
   "source": [
    "ops, params = tp.utils.count_ops_and_params(distilled_model, input_example)\n",
    "print(f\"Distilled model complexity: {ops/1e6} MMAC, {params/1e6} M params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ð¼, Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ð¾ÑÐ»Ðµ Ð´Ð¸ÑÑ‚Ð¸Ð»Ð»ÑÑ†Ð¸Ð¸ Ð¸Ð¼ÐµÐµÑ‚ Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ SegformerLayer Ð² block-Ðµ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegformerForSemanticSegmentation(\n",
       "  (segformer): SegformerModel(\n",
       "    (encoder): SegformerEncoder(\n",
       "      (patch_embeddings): ModuleList(\n",
       "        (0): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.03333333507180214)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.06666666269302368)\n",
       "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): ModuleList(\n",
       "        (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode_head): SegformerDecodeHead(\n",
       "    (linear_c): ModuleList(\n",
       "      (0): SegformerMLP(\n",
       "        (proj): Linear(in_features=32, out_features=256, bias=True)\n",
       "      )\n",
       "      (1): SegformerMLP(\n",
       "        (proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): SegformerMLP(\n",
       "        (proj): Linear(in_features=160, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): SegformerMLP(\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzLU9tZUwccp"
   },
   "source": [
    "## Magnitude pruning (10 Ð±Ð°Ð»Ð»Ð¾Ð²)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð’Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚Ðµ one-shot Ð¿Ñ€ÑƒÐ½Ð¸Ð½Ð³ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ð¾ L2 Ð½Ð¾Ñ€Ð¼Ðµ Ð²ÐµÑÐ¾Ð² Ð² uniform Ñ€ÐµÐ¶Ð¸Ð¼Ðµ. ÐŸÐ¾Ð¼Ð½Ð¸Ñ‚Ðµ, Ñ‡Ñ‚Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ ÑÐ»Ð¾Ð¹ Ð¶ÐµÐ»Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð½Ðµ Ð¿Ñ€ÑƒÐ½Ð¸Ñ‚ÑŒ. ÐŸÐ¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ pruning_ratio=0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model_l2(model):\n",
    "    # Ð²Ð¾Ñ‚ Ñ‚ÑƒÑ‚ Ð½Ð°Ð´Ð¾ Ð²Ð¾ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¾Ð¹ torch pruning\n",
    "\n",
    "    example_inputs = torch.randn(1, 3, 512, 512, device=\"cuda\")\n",
    "    #L2 Magnitude prunning\n",
    "    imp = tp.importance.MagnitudeImportance(p=2)\n",
    "\n",
    "    # Ignore some layers, e.g., the output layer\n",
    "    ignored_layers = [model.decode_head]\n",
    "\n",
    "    pruner = tp.pruner.MagnitudePruner(\n",
    "        model,\n",
    "        example_inputs,\n",
    "        imp,\n",
    "        pruning_ratio = 0.75,\n",
    "        pruning_ratio_dict = {},\n",
    "        ignored_layers=ignored_layers,\n",
    "    )\n",
    "    pruner.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "pruned_model = prune_model_l2(deepcopy(distilled_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 16384, 1, 32]' is invalid for input of size 131072",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ð¼, Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ Ð»Ð¸ Ð½Ð°ÑˆÐ° Ð·Ð°Ð¿Ñ€ÑƒÐ½ÐµÐ½Ð½Ð°Ñ ÑÐµÑ‚ÑŒ\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpruned_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:793\u001b[0m, in \u001b[0;36mSegformerForSemanticSegmentation.forward\u001b[0;34m(self, pixel_values, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    788\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    789\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    790\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    791\u001b[0m )\n\u001b[0;32m--> 793\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# we need the intermediate hidden states\u001b[39;49;00m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m encoder_hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mhidden_states \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    802\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_head(encoder_hidden_states)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:550\u001b[0m, in \u001b[0;36mSegformerModel.forward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    545\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    546\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    547\u001b[0m )\n\u001b[1;32m    548\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 550\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:427\u001b[0m, in \u001b[0;36mSegformerEncoder.forward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# second, send embeddings through blocks\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(block_layer):\n\u001b[0;32m--> 427\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:334\u001b[0m, in \u001b[0;36mSegformerLayer.forward\u001b[0;34m(self, hidden_states, height, width, output_attentions)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, height, width, output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 334\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# in Segformer, layernorm is applied before self-attention\u001b[39;49;00m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    342\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:272\u001b[0m, in \u001b[0;36mSegformerAttention.forward\u001b[0;34m(self, hidden_states, height, width, output_attentions)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, height, width, output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 272\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    275\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:191\u001b[0m, in \u001b[0;36mSegformerEfficientSelfAttention.forward\u001b[0;34m(self, hidden_states, height, width, output_attentions)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    186\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    190\u001b[0m ):\n\u001b[0;32m--> 191\u001b[0m     query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose_for_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msr_ratio \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    194\u001b[0m         batch_size, seq_len, num_channels \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:181\u001b[0m, in \u001b[0;36mSegformerEfficientSelfAttention.transpose_for_scores\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose_for_scores\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    180\u001b[0m     new_shape \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_head_size)\n\u001b[0;32m--> 181\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 16384, 1, 32]' is invalid for input of size 131072"
     ]
    }
   ],
   "source": [
    "# ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ð¼, Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ Ð»Ð¸ Ð½Ð°ÑˆÐ° Ð·Ð°Ð¿Ñ€ÑƒÐ½ÐµÐ½Ð½Ð°Ñ ÑÐµÑ‚ÑŒ\n",
    "pruned_model(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÐŸÐ¾Ñ‡Ð¸Ð½Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŒÐºÑƒ (20 Ð±Ð°Ð»Ð»Ð¾Ð²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð»Ð¾Ð³ Ð¾ÑˆÐ¸Ð±ÐºÐ¸, Ð¸ Ð¿Ð¾Ð¹Ð¼Ð¸Ñ‚Ðµ Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿ÐµÑ€ÐµÑÑ‚Ð°Ð»Ð° Ð·Ð°Ð¿ÑƒÑÐºÐ°Ñ‚ÑŒÑÑ Ð¿Ð¾ÑÐ»Ðµ Ð¿Ñ€ÑƒÐ½Ð¸Ð½Ð³Ð°\n",
    "# ÐŸÐ¾Ð´ÑÐºÐ°Ð·ÐºÐ°, ÑÑ‚Ð¾ ÑÐ²ÑÐ·Ð°Ð½Ð¾ ÑÐ¾ ÑÐ»Ð¾ÐµÐ¼ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ Ð¸ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð¾Ð¼ Ð³Ð¾Ð»Ð¾Ð²\n",
    "\n",
    "def fix_attention_layer(pruned_model):\n",
    "    num_heads = {}\n",
    "    for m in pruned_model.modules():\n",
    "        if isinstance(m, SegformerEfficientSelfAttention):\n",
    "            num_heads[m.query] = m.num_attention_heads\n",
    "            num_heads[m.key] = m.num_attention_heads\n",
    "            num_heads[m.value] = m.num_attention_heads\n",
    "\n",
    "    for m in pruned_model.modules():\n",
    "        if isinstance(m, SegformerEfficientSelfAttention):\n",
    "            print(m)\n",
    "            print(\"num_heads:\", m.num_attention_heads, 'head_dims:', m.attention_head_size, 'all_head_size:', m.all_head_size, '=>')\n",
    "            m.num_attention_heads = num_heads[m.query]\n",
    "            m.attention_head_size = m.query.out_features // m.num_attention_heads\n",
    "            m.all_head_size = m.query.out_features\n",
    "            print(\"num_heads:\", m.num_attention_heads, 'head_dims:', m.attention_head_size, 'all_head_size:', m.all_head_size)\n",
    "    \n",
    "    return pruned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegformerEfficientSelfAttention(\n",
      "  (query): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (key): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (value): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (sr): Conv2d(8, 8, kernel_size=(8, 8), stride=(8, 8))\n",
      "  (layer_norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "num_heads: 1 head_dims: 32 all_head_size: 32 =>\n",
      "num_heads: 1 head_dims: 8 all_head_size: 8\n",
      "SegformerEfficientSelfAttention(\n",
      "  (query): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (key): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (value): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (sr): Conv2d(16, 16, kernel_size=(4, 4), stride=(4, 4))\n",
      "  (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "num_heads: 2 head_dims: 32 all_head_size: 64 =>\n",
      "num_heads: 2 head_dims: 8 all_head_size: 16\n",
      "SegformerEfficientSelfAttention(\n",
      "  (query): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (key): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (value): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (sr): Conv2d(40, 40, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "num_heads: 5 head_dims: 32 all_head_size: 160 =>\n",
      "num_heads: 5 head_dims: 8 all_head_size: 40\n",
      "SegformerEfficientSelfAttention(\n",
      "  (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "num_heads: 8 head_dims: 32 all_head_size: 256 =>\n",
      "num_heads: 8 head_dims: 8 all_head_size: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SemanticSegmenterOutput(loss=None, logits=tensor([[[[-0.9120, -0.9594, -1.2067,  ..., -0.8537, -0.9097, -0.8198],\n",
       "          [-0.8806, -0.8767, -1.2150,  ..., -1.0846, -0.9317, -1.0418],\n",
       "          [-0.8034, -0.9083, -1.1288,  ..., -0.6273, -0.8092, -0.8748],\n",
       "          ...,\n",
       "          [-0.5124, -0.5545, -0.7156,  ..., -0.6038, -1.2535, -0.7603],\n",
       "          [-0.5662, -0.6462, -0.9241,  ..., -0.6759, -0.8009, -0.7472],\n",
       "          [-0.5649, -0.6868, -0.7955,  ..., -0.5920, -0.9182, -0.7973]],\n",
       "\n",
       "         [[ 0.9185,  0.9346,  1.1449,  ...,  0.7656,  0.8672,  0.7434],\n",
       "          [ 0.8215,  0.8072,  1.2135,  ...,  0.9763,  0.9648,  1.0666],\n",
       "          [ 0.7870,  0.9248,  1.0535,  ...,  0.6151,  0.7583,  0.9625],\n",
       "          ...,\n",
       "          [ 0.5162,  0.5852,  0.6627,  ...,  0.6102,  1.2155,  0.6626],\n",
       "          [ 0.5043,  0.6721,  0.8944,  ...,  0.7548,  0.7050,  0.7460],\n",
       "          [ 0.5812,  0.7473,  0.9994,  ...,  0.5661,  0.8649,  0.8011]]]],\n",
       "       device='cuda:0', grad_fn=<ConvolutionBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ Ð¿Ð¾ÑÐ»Ðµ Ñ„Ð¸ÐºÑÐ°\n",
    "pruned_model = fix_attention_layer(pruned_model)\n",
    "pruned_model(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled model complexity (After magnitude pruning): 4483.917952 MMAC, 0.42249 M params\n"
     ]
    }
   ],
   "source": [
    "# ÐžÑ†ÐµÐ½Ð¸Ð¼ Ð²Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð²ÑˆÐµÐ¹ÑÑ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "ops, params = tp.utils.count_ops_and_params(pruned_model, input_example)\n",
    "print(f\"Distilled model complexity (After magnitude pruning): {ops/1e6} MMAC, {params/1e6} M params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ ÑƒÐ¼ÐµÐ½ÑŒÑˆÐ°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ ÐµÑ‰Ðµ ÑÐ¸Ð»ÑŒÐ½ÐµÐµ, Ð·Ð°Ð¿Ñ€ÑƒÐ½Ð¸Ð² Ð³Ð¾Ð»Ð¾Ð²Ñ‹ Ð² attention.\n",
    "# Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» torch pruning ÑÑ‚Ð¾ Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚, Ð¾Ð´Ð½Ð°ÐºÐ¾ ÑÑ‚Ð¾ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ Ð² transformers\n",
    "# Ð”Ð»Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ð½Ð°Ð¸Ð¼ÐµÐ½ÐµÐµ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ñ… Ð³Ð¾Ð»Ð¾Ð² Ð¼Ð¾Ð¶Ð½Ð¾ Ð²Ð¾ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ L2 Ð½Ð¾Ñ€Ð¼Ð¾Ð¹ Ð²ÐµÑÐ¾Ð². \n",
    "# ÐœÑ‹ Ð¶Ðµ Ñ‚ÑƒÑ‚ Ð²Ñ‹ÐºÐ¸Ð½ÐµÐ¼ Ð²ÑÐµ, ÐºÑ€Ð¾Ð¼Ðµ Ð½ÑƒÐ»ÐµÐ²Ð¾Ð¹.\n",
    "\n",
    "pruned_model.segformer.encoder.block[1][0].attention.prune_heads([1])\n",
    "pruned_model.segformer.encoder.block[2][0].attention.prune_heads([1,2,3,4])\n",
    "pruned_model.segformer.encoder.block[3][0].attention.prune_heads([1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled model complexity (After magnitude pruning): 4475.856736 MMAC, 0.402234 M params\n"
     ]
    }
   ],
   "source": [
    "# Ð¡Ð½Ð¾Ð²Ð° Ð¾Ñ†ÐµÐ½Ð¸Ð¼ Ð²Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ\n",
    "ops, params = tp.utils.count_ops_and_params(pruned_model, input_example)\n",
    "print(f\"Distilled model complexity (After magnitude pruning): {ops/1e6} MMAC, {params/1e6} M params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Ð”Ð¾Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ñ€ÑƒÐ½ÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (5 Ð±Ð°Ð»Ð»Ð¾Ð²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ð¿ÐµÑ€ÐµÐ½ÐµÑÐ¸Ñ‚Ðµ ÑÐ²Ð¾Ð¹ Ñ‚Ñ€ÐµÐ¹Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ Ð¸Ð· Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÐµÐ¹ Ð´Ð¾Ð¼Ð°ÑˆÐºÐ¸ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» Ð¸ Ð²Ð¾ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚ÐµÑÑŒ Ð¸Ð¼\n",
    "from utils.train import TrainParams, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = TrainParams(\n",
    "    n_epochs=1,\n",
    "    lr=12e-5,\n",
    "    batch_size=24,\n",
    "    n_workers=8,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    temperature=3,\n",
    "    loss_weight=0.5,\n",
    "    last_layer_loss_weight=0.5,\n",
    "    intermediate_attn_layers_weights=(0.5, 0.5, 0.5, 0.5),\n",
    "    intermediate_feat_layers_weights=(0.5, 0.5, 0.5, 0.5)\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    teacher_attentions = baseline_model(pixel_values=torch.ones(1, 3, 512, 512).to(train_params.device), output_attentions=True).attentions\n",
    "    student_attentions = pruned_model(pixel_values=torch.ones(1, 3, 512, 512).to(train_params.device), output_attentions=True).attentions\n",
    "\n",
    "    assert len(teacher_attentions) == 8\n",
    "    assert len(student_attentions) == 4\n",
    "\n",
    "student_teacher_attention_mapping = {i: i*2 + 1 for i in range(4)}\n",
    "\n",
    "tb_writer = SummaryWriter(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/transformers/models/segformer/feature_extraction_segformer.py:28: FutureWarning: The class SegformerFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use SegformerImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/transformers/models/segformer/image_processing_segformer.py:102: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n",
      "total loss: -61848.336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [10:43<00:00,  1.78it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.8653744293493053\n",
      "Mean accuracy: 0.9268792786380723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/transformers/models/segformer/feature_extraction_segformer.py:28: FutureWarning: The class SegformerFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use SegformerImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/transformers/models/segformer/image_processing_segformer.py:102: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n",
      "total loss: -68095.578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [11:24<00:00,  1.68it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.8938826308531549\n",
      "Mean accuracy: 0.9431564493025576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "total loss: -65177.156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [11:25<00:00,  1.67it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.9135316849328331\n",
      "Mean accuracy: 0.9543163906238968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "total loss: -66662.406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [11:08<00:00,  1.72it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.9156998973348219\n",
      "Mean accuracy: 0.9564662425854906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "total loss: -65914.555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [11:02<00:00,  1.73it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.9211714091611245\n",
      "Mean accuracy: 0.9577187579337156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "total loss: -67122.961: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [11:19<00:00,  1.69it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.931900305332622\n",
      "Mean accuracy: 0.9641197057345005\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    teacher_model=baseline_model,\n",
    "    student_model=pruned_model,\n",
    "    train_params=train_params,\n",
    "    student_teacher_attention_mapping=student_teacher_attention_mapping,\n",
    "    tb_writer=tb_writer,\n",
    "    save_dir=save_dir,\n",
    "    id2label=id2label\n",
    ")\n",
    "\n",
    "train_params.n_epochs=5\n",
    "train_params.lr=18e-5\n",
    "\n",
    "train(\n",
    "    teacher_model=baseline_model,\n",
    "    student_model=pruned_model,\n",
    "    train_params=train_params,\n",
    "    student_teacher_attention_mapping=student_teacher_attention_mapping,\n",
    "    tb_writer=tb_writer,\n",
    "    save_dir=save_dir,\n",
    "    id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taylor pruning (15 Ð±Ð°Ð»Ð»Ð¾Ð²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 16899571712, Reserved: 4955570176, Allocated: 2996960768, Free: 1958609408\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Print current GPU memory usage\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "\n",
    "print(f'Total: {t}, Reserved: {r}, Allocated: {a}, Free: {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð”Ð°Ð»ÐµÐµ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð¿Ñ€ÑƒÐ½Ð¸Ð½Ð³ Ð¿Ð¾ Taylor ÐºÑ€Ð¸Ñ‚ÐµÑ€Ð¸ÑŽ Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚Ð¸, Ð¸ ÑÑ€Ð°Ð²Ð½Ð¸Ñ‚ÑŒ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð¿Ð¾ÑÐ»Ðµ Ñ‚ÑŽÐ½Ð¸Ð½Ð³Ð°. Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ Ð¿Ñ€ÑƒÐ½Ð¸Ð½Ð³Ð° Ð¸ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ  (uniform) Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ñ‚Ð°ÐºÐ¾Ð¹ Ð¶Ðµ, ÐºÐ°Ðº Ð´Ð»Ñ L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_fuse.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "baseline_model = init_model_with_pretrain(label2id=label2id, id2label=id2label, pretrain_path=baseline_path).cuda()\n",
    "distilled_model = init_model_student_with_pretrain(distilled_ckpt).cuda()\n",
    "pruned_model = deepcopy(distilled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model_taylor(model):\n",
    "    # Ð²Ð¾Ñ‚ Ñ‚ÑƒÑ‚ Ð½Ð°Ð´Ð¾ Ð²Ð¾ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¾Ð¹ torch pruning\n",
    "    # Ñ‚ÑƒÑ‚ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ÑÑ pruner, Ð° Ð½Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŒÐºÐ° \n",
    "\n",
    "    example_inputs = torch.randn(1, 3, 512, 512, device=\"cuda\")\n",
    "\n",
    "    # Ignore some layers, e.g., the output layer\n",
    "    ignored_layers = [model.decode_head]\n",
    "\n",
    "    #Taylor prunning\n",
    "    imp = tp.importance.TaylorImportance()\n",
    "\n",
    "    pruner = tp.pruner.MetaPruner(\n",
    "                model, \n",
    "                example_inputs, \n",
    "                global_pruning=False, # If False, a uniform pruning ratio will be assigned to different layers.\n",
    "                importance=imp, # importance criterion for parameter selection\n",
    "                pruning_ratio=0.75, # target pruning ratio\n",
    "                ignored_layers=ignored_layers,\n",
    "                output_transform=lambda out: out.logits.sum())\n",
    "\n",
    "    return pruner\n",
    "\n",
    "pruner = prune_model_taylor(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ð¼ ÐºÑ€Ð¸Ñ‚ÐµÑ€Ð¸Ð¹ Ð¸ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ð¿Ñ€ÑƒÐ½Ð¸Ð½Ð³Ð°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð”Ð»Ñ Ð¿Ñ€ÑƒÐ½Ð¸Ð½Ð³Ð° Ð¿Ð¾ Ð¢ÐµÐ¹Ð»Ð¾Ñ€Ñƒ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÑŒ Ð³Ñ€Ð°Ð´Ð¸ÐµÐ½Ñ‚Ñ‹ Ð½Ð° Ð²ÐµÑÐ°Ñ…, Ð¾Ð½Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸ Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚Ð¸ ÐºÐ°Ð½Ð°Ð»Ð¾Ð²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_model(model, train_loader, device):\n",
    "\n",
    "    model.zero_grad()\n",
    "    print(\"Accumulating gradients for taylor pruning...\")\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for idx, batch in pbar:\n",
    "        imgs = batch['pixel_values'].to(device)\n",
    "        lbls = batch['labels'].to(device)\n",
    "        loss = model(\n",
    "                pixel_values=imgs, \n",
    "                labels=lbls\n",
    "            ).loss\n",
    "        \n",
    "        loss.backward()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÐžÐ±Ñ€Ð°Ñ‚Ð¸Ñ‚Ðµ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ, Ñƒ Ð²Ð°Ñ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ð¿Ñ€ÑƒÐ½Ð¸Ð½Ð³Ð° Ð¸ ÐµÐ³Ð¾ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ€Ð°Ð·Ð½ÐµÑÐµÐ½Ñ‹ Ð¿Ð¾ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑÐ¼.\n",
    "def apply_taylor_pruning(pruner):\n",
    "    for g in pruner.step(interactive=True):\n",
    "        g.prune()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating gradients for taylor pruning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3443/3443 [09:45<00:00,  5.88it/s]\n"
     ]
    }
   ],
   "source": [
    "pruned_model = calibrate_model(pruned_model, train_dataloader, \"cuda\")\n",
    "apply_taylor_pruning(pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 16384, 1, 32]' is invalid for input of size 131072",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ð¼, Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ Ð»Ð¸ Ð½Ð°ÑˆÐ° Ð·Ð°Ð¿Ñ€ÑƒÐ½ÐµÐ½Ð½Ð°Ñ ÑÐµÑ‚ÑŒ\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpruned_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:793\u001b[0m, in \u001b[0;36mSegformerForSemanticSegmentation.forward\u001b[0;34m(self, pixel_values, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    788\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    789\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    790\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    791\u001b[0m )\n\u001b[0;32m--> 793\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# we need the intermediate hidden states\u001b[39;49;00m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m encoder_hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mhidden_states \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    802\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_head(encoder_hidden_states)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:550\u001b[0m, in \u001b[0;36mSegformerModel.forward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    545\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    546\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    547\u001b[0m )\n\u001b[1;32m    548\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 550\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:427\u001b[0m, in \u001b[0;36mSegformerEncoder.forward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# second, send embeddings through blocks\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(block_layer):\n\u001b[0;32m--> 427\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:334\u001b[0m, in \u001b[0;36mSegformerLayer.forward\u001b[0;34m(self, hidden_states, height, width, output_attentions)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, height, width, output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 334\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# in Segformer, layernorm is applied before self-attention\u001b[39;49;00m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    342\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:272\u001b[0m, in \u001b[0;36mSegformerAttention.forward\u001b[0;34m(self, hidden_states, height, width, output_attentions)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, height, width, output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 272\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    275\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:191\u001b[0m, in \u001b[0;36mSegformerEfficientSelfAttention.forward\u001b[0;34m(self, hidden_states, height, width, output_attentions)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    186\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    190\u001b[0m ):\n\u001b[0;32m--> 191\u001b[0m     query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose_for_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msr_ratio \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    194\u001b[0m         batch_size, seq_len, num_channels \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/segformer/modeling_segformer.py:181\u001b[0m, in \u001b[0;36mSegformerEfficientSelfAttention.transpose_for_scores\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose_for_scores\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    180\u001b[0m     new_shape \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_head_size)\n\u001b[0;32m--> 181\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 16384, 1, 32]' is invalid for input of size 131072"
     ]
    }
   ],
   "source": [
    "# ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ð¼, Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ Ð»Ð¸ Ð½Ð°ÑˆÐ° Ð·Ð°Ð¿Ñ€ÑƒÐ½ÐµÐ½Ð½Ð°Ñ ÑÐµÑ‚ÑŒ\n",
    "pruned_model(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‚Ð¾Ñ‚ Ð¶Ðµ Ñ„Ð¸ÐºÑ, ÐºÐ°Ðº Ð´Ð»Ñ Ð¿Ñ€ÑƒÐ½Ð¸Ð½Ð³Ð° Ð¿Ð¾ L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegformerEfficientSelfAttention(\n",
      "  (query): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (key): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (value): Linear(in_features=8, out_features=8, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (sr): Conv2d(8, 8, kernel_size=(8, 8), stride=(8, 8))\n",
      "  (layer_norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "num_heads: 1 head_dims: 32 all_head_size: 32 =>\n",
      "num_heads: 1 head_dims: 8 all_head_size: 8\n",
      "SegformerEfficientSelfAttention(\n",
      "  (query): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (key): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (value): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (sr): Conv2d(16, 16, kernel_size=(4, 4), stride=(4, 4))\n",
      "  (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "num_heads: 2 head_dims: 32 all_head_size: 64 =>\n",
      "num_heads: 2 head_dims: 8 all_head_size: 16\n",
      "SegformerEfficientSelfAttention(\n",
      "  (query): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (key): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (value): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (sr): Conv2d(40, 40, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (layer_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "num_heads: 5 head_dims: 32 all_head_size: 160 =>\n",
      "num_heads: 5 head_dims: 8 all_head_size: 40\n",
      "SegformerEfficientSelfAttention(\n",
      "  (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "num_heads: 8 head_dims: 32 all_head_size: 256 =>\n",
      "num_heads: 8 head_dims: 8 all_head_size: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SemanticSegmenterOutput(loss=None, logits=tensor([[[[-1.2204, -1.2700, -1.3748,  ..., -1.0825, -1.0776, -1.0892],\n",
       "          [-1.2702, -1.1465, -1.2638,  ..., -1.2320, -0.9118, -0.9954],\n",
       "          [-1.1736, -1.1875, -1.3741,  ..., -0.6371, -0.8822, -0.8666],\n",
       "          ...,\n",
       "          [-0.8053, -0.8706, -1.1042,  ..., -0.5968, -1.2919, -0.6706],\n",
       "          [-0.9656, -0.9587, -1.3761,  ..., -0.7648, -0.9936, -0.6254],\n",
       "          [-0.9083, -1.0362, -1.3280,  ..., -0.7713, -1.0960, -0.7790]],\n",
       "\n",
       "         [[ 1.2403,  1.2960,  1.3943,  ...,  1.0853,  1.1161,  1.0943],\n",
       "          [ 1.2749,  1.1636,  1.3368,  ...,  1.2758,  1.0029,  1.2188],\n",
       "          [ 1.1994,  1.2574,  1.4077,  ...,  0.7134,  0.9193,  0.9919],\n",
       "          ...,\n",
       "          [ 0.8889,  0.9950,  1.1544,  ...,  0.7167,  1.4545,  0.7343],\n",
       "          [ 1.0120,  1.0776,  1.4508,  ...,  0.9096,  1.0147,  0.7238],\n",
       "          [ 0.9933,  1.1896,  1.5637,  ...,  0.8353,  1.1530,  0.8827]]]],\n",
       "       device='cuda:0', grad_fn=<ConvolutionBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ð£Ð±ÐµÐ´Ð¸Ñ‚ÐµÑÑŒ, Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ Ð¿Ð¾ÑÐ»Ðµ Ñ„Ð¸ÐºÑÐ°\n",
    "pruned_model = fix_attention_layer(pruned_model)\n",
    "pruned_model(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled model complexity (After taylor pruning): 4483.917952 MMAC, 0.42249 M params\n"
     ]
    }
   ],
   "source": [
    "# ÐžÑ†ÐµÐ½Ð¸Ð¼ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸\n",
    "ops, params = tp.utils.count_ops_and_params(pruned_model, input_example)\n",
    "print(f\"Distilled model complexity (After taylor pruning): {ops/1e6} MMAC, {params/1e6} M params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð’Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ð¼ Ð´Ð¾Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ, Ð¸ ÑÑ€Ð°Ð²Ð½Ð¸Ð¼ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params.n_epochs=1\n",
    "train_params.lr=12e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../../assignment2/runs//taylor_equal_pruning'\n",
    "tb_writer = SummaryWriter(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/transformers/models/segformer/feature_extraction_segformer.py:28: FutureWarning: The class SegformerFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use SegformerImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/transformers/models/segformer/image_processing_segformer.py:102: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n",
      "total loss: -67187.289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [10:58<00:00,  1.74it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.8826069606563256\n",
      "Mean accuracy: 0.936557109570126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/transformers/models/segformer/feature_extraction_segformer.py:28: FutureWarning: The class SegformerFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use SegformerImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/transformers/models/segformer/image_processing_segformer.py:102: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n",
      "total loss: -67636.344: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [11:04<00:00,  1.73it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.9000582493453515\n",
      "Mean accuracy: 0.9458899839746695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "total loss: -66479.633: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [10:54<00:00,  1.76it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.9254577826363342\n",
      "Mean accuracy: 0.9600806486478971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "total loss: -65710.164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [10:24<00:00,  1.84it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.9379602108055853\n",
      "Mean accuracy: 0.9675411037730601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "total loss: -66448.703: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [10:22<00:00,  1.85it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.9464933973183418\n",
      "Mean accuracy: 0.9722341138546797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "total loss: -67671.445: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1148/1148 [11:11<00:00,  1.71it/s]\n",
      "/home/gvasserm/.local/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for mean_iou contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/mean_iou/mean_iou.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.9437714826851367\n",
      "Mean accuracy: 0.9703885253869773\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    teacher_model=baseline_model,\n",
    "    student_model=pruned_model,\n",
    "    train_params=train_params,\n",
    "    student_teacher_attention_mapping=student_teacher_attention_mapping,\n",
    "    tb_writer=tb_writer,\n",
    "    save_dir=save_dir,\n",
    "    id2label=id2label\n",
    ")\n",
    "\n",
    "train_params.n_epochs=5\n",
    "train_params.lr=18e-5\n",
    "\n",
    "train(\n",
    "    teacher_model=baseline_model,\n",
    "    student_model=pruned_model,\n",
    "    train_params=train_params,\n",
    "    student_teacher_attention_mapping=student_teacher_attention_mapping,\n",
    "    tb_writer=tb_writer,\n",
    "    save_dir=save_dir,\n",
    "    id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Experiments Hyperparameter Tunning Notebook\n",
    "\n",
    "Model           Size (M)  Mean_iou Mean_acc\n",
    "Baseline\t    3.714\t   0.9825\t0.991\n",
    "Distilled\t    2.298\t   0.9647\t0.981\n",
    "MagPrunned      0.422      0.9319   0.964\n",
    "TaylorPrunned   0.422      0.9437   0.970\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "022d35b20c08415a89a7f5b90e3b31f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04f845521ec6415caa300af136d11252": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0633e526422442e09eb31970508c10b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c12bee18a30441db7f670056ca48eeb",
      "max": 3443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fff029bc967e4678a3992e1fd0c404a2",
      "value": 201
     }
    },
    "08b014f543844bc7ab9cb5d8a0ff9b06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23151e83a7da4541bd0449db0535506e",
      "max": 3443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb8faad285b8488bbfc605402076470a",
      "value": 201
     }
    },
    "11f4590f937d4b989829a66ddd57c179": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1725238aed0d47769f5c940f28b08fd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_397206a95b1b4f459b7f415acd8779c3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_04f845521ec6415caa300af136d11252",
      "value": "totalâ€‡loss:â€‡0.047:â€‡â€‡â€‡6%"
     }
    },
    "1f19ec67321445cbb9cb1c04ade7a1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22c9522d0565426284fd7627e10b27ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba7171d3e9da49768527816de7ae9da7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_11f4590f937d4b989829a66ddd57c179",
      "value": "totalâ€‡loss:â€‡0.046:â€‡â€‡â€‡6%"
     }
    },
    "23151e83a7da4541bd0449db0535506e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "397206a95b1b4f459b7f415acd8779c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c12bee18a30441db7f670056ca48eeb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5181e7a336c74b51b3fe5ac021d64dd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53a8a255843e48ddaa273da32ccda138": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "557b85d45211403eaa3cfe317bc10902": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7b3c79d8d5e4f248fa6e1ec8b321909",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_843395b0d5fc4dfa996d145eace0521e",
      "value": "totalâ€‡loss:â€‡0.054:â€‡â€‡â€‡1%"
     }
    },
    "59b86a659eaa42a8b3fe423049c010d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e6283a0a6be495c8883c2649b156357": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "608d3f8145104c7dbed43db515d7d904": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "694ea66e86014a0ab6033a78aa6c5bee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb375544d12e460b9f066f9c84c013cc",
       "IPY_MODEL_f735779920194b9284275ddfe8ce644b",
       "IPY_MODEL_9087c3e14b56406280c2495f2aab9121"
      ],
      "layout": "IPY_MODEL_022d35b20c08415a89a7f5b90e3b31f9"
     }
    },
    "6b18b3438d8c41ae80c4de0b4c29f0b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb8cb76377bd44f2a28310bb15ab6ed3",
      "max": 3443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2c5d925aec043bb81d343610a016934",
      "value": 39
     }
    },
    "6e6dfe7d35e54cfcb236d25ff9fe89e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78eb20385ecf494a8fbb9611cbd8d3c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "843395b0d5fc4dfa996d145eace0521e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ad0d82a5e1844298f01cfe4e454c653": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1725238aed0d47769f5c940f28b08fd1",
       "IPY_MODEL_08b014f543844bc7ab9cb5d8a0ff9b06",
       "IPY_MODEL_9ca950c0259045459dab7204516ad9ca"
      ],
      "layout": "IPY_MODEL_b31a77c9baa4475b8448919b88e7fd6f"
     }
    },
    "9087c3e14b56406280c2495f2aab9121": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f19ec67321445cbb9cb1c04ade7a1ab",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f452460548aa42fc8e62757ae9d254df",
      "value": "â€‡201/3443â€‡[01:35&lt;27:41,â€‡â€‡1.95it/s]"
     }
    },
    "972e7cc3e253409da6b8de25d0d5e8bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ca950c0259045459dab7204516ad9ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0c37e6f14224e9f8c64f049494bb925",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_59b86a659eaa42a8b3fe423049c010d1",
      "value": "â€‡201/3443â€‡[01:36&lt;22:30,â€‡â€‡2.40it/s]"
     }
    },
    "9f1339b2f23c4c45bb84da41c6f78ede": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b31a77c9baa4475b8448919b88e7fd6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba7171d3e9da49768527816de7ae9da7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb8cb76377bd44f2a28310bb15ab6ed3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c447cf5571504d26ac64424aaeb61583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5181e7a336c74b51b3fe5ac021d64dd7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5e6283a0a6be495c8883c2649b156357",
      "value": "â€‡201/3443â€‡[01:37&lt;23:39,â€‡â€‡2.28it/s]"
     }
    },
    "c7b236c5e51142e28186dbdb8195ffb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7b3c79d8d5e4f248fa6e1ec8b321909": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca3b565d4da94f5a88b71efc962723a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e6dfe7d35e54cfcb236d25ff9fe89e3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_608d3f8145104c7dbed43db515d7d904",
      "value": "â€‡39/3443â€‡[00:24&lt;26:06,â€‡â€‡2.17it/s]"
     }
    },
    "cb375544d12e460b9f066f9c84c013cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78eb20385ecf494a8fbb9611cbd8d3c3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c7b236c5e51142e28186dbdb8195ffb2",
      "value": "totalâ€‡loss:â€‡0.045:â€‡â€‡â€‡6%"
     }
    },
    "e5db82c5d0a345d7aab734a928db4958": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_557b85d45211403eaa3cfe317bc10902",
       "IPY_MODEL_6b18b3438d8c41ae80c4de0b4c29f0b9",
       "IPY_MODEL_ca3b565d4da94f5a88b71efc962723a4"
      ],
      "layout": "IPY_MODEL_9f1339b2f23c4c45bb84da41c6f78ede"
     }
    },
    "e9bd932fa62e4ea5844c1a5b69199e91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb8faad285b8488bbfc605402076470a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f0c37e6f14224e9f8c64f049494bb925": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f25d2647e2314870946df80630e0182f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_22c9522d0565426284fd7627e10b27ca",
       "IPY_MODEL_0633e526422442e09eb31970508c10b9",
       "IPY_MODEL_c447cf5571504d26ac64424aaeb61583"
      ],
      "layout": "IPY_MODEL_972e7cc3e253409da6b8de25d0d5e8bb"
     }
    },
    "f2c5d925aec043bb81d343610a016934": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f452460548aa42fc8e62757ae9d254df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f735779920194b9284275ddfe8ce644b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9bd932fa62e4ea5844c1a5b69199e91",
      "max": 3443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_53a8a255843e48ddaa273da32ccda138",
      "value": 201
     }
    },
    "fff029bc967e4678a3992e1fd0c404a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
