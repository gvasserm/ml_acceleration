{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "febba31b-151d-45dc-bffd-c8c881fe287b",
   "metadata": {},
   "source": [
    "# OpenVINO (50 баллов)\n",
    "\n",
    "## Установим Зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d41e2-e0ec-4d0a-8500-ce5542cada38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U openvino nncf\n",
    "# # или пре-релизная версия:\n",
    "# !pip install --pre -U openvino --extra-index-url https://storage.openvinotoolkit.org/simple/wheels/nightly git+https://github.com/openvinotoolkit/nncf.git\n",
    "\n",
    "# !pip install transformers[torch] datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e47b0-17c4-433a-9862-dbcc341fbe36",
   "metadata": {},
   "source": [
    "## Скачиваем Предобученную Модель\n",
    "\n",
    "Выберите классификационную модель из [Huggingface Hub](https://huggingface.co/models?pipeline_tag=text-classification&sort=trending&search=sst2), либо возьмите модель по умолчанию. Этот ноутбук сделан с рассчётом модель, натренированную на [sst2](https://huggingface.co/datasets/nyu-mll/glue/viewer/sst2) датасете. Если выберете другую модель и датасет, перепешите соответствующие блоки проверки accuracy. Единственное ограничение - модель должна быть трансформер энкодером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02fe5515-d107-4218-809e-f2dbde0c29aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_id = \"philschmid/MiniLM-L6-H384-uncased-sst2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "hf_model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccafc42d-44e3-4551-928b-b35f72f5739a",
   "metadata": {},
   "source": [
    "## Конвертируем Модель в OpenVINO (5 баллов)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eded1b8-997a-4406-90b9-c2160c53c55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apaniuko/python/deepschool/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4225: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<ConstOutput: names[logits] shape[?,2] type: f32>: array([[ 1.1164335, -1.1053413]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "\n",
    "example_input = {**tokenizer(\"test\", return_tensors=\"pt\")}\n",
    "ov_model = ov.convert_model(hf_model, example_input=example_input)\n",
    "ov.save_model(ov_model, 'bert.xml')\n",
    "\n",
    "compiled_model = ov.compile_model(ov_model)\n",
    "print(compiled_model(example_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad7b85-8ec6-4ba6-9cd7-18c859df16aa",
   "metadata": {},
   "source": [
    "Провалидируем предсказания сконвертированной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fb45710-d3f2-41bc-8d67-269b8b12abf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch accuracy:  0.9013761467889908\n",
      "OpenVINO accuracy: 0.9013761467889908\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "\n",
    "\n",
    "val_dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "@torch.no_grad\n",
    "def accuracy_evaluate(model, dataset=val_dataset, accuracy=accuracy):   \n",
    "    for sample in dataset:\n",
    "        tokenized = {**tokenizer(sample[\"sentence\"], return_tensors=\"pt\")}\n",
    "        logits = model(tokenized)[\"logits\"]\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        accuracy.add(references=sample[\"label\"], predictions=pred)\n",
    "\n",
    "    return accuracy.compute()[\"accuracy\"]\n",
    "\n",
    "\n",
    "print(f\"PyTorch accuracy:  {accuracy_evaluate(lambda x: hf_model(**x))}\")\n",
    "print(f\"OpenVINO accuracy: {accuracy_evaluate(compiled_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215c7a2-4011-4f61-94e8-cb48cc8c4312",
   "metadata": {},
   "source": [
    "## Benchmark (5 баллов)\n",
    "\n",
    "Добавьте несколько инференсов в бенчмарк для того, чтобы получить более точные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378d80b6-9988-4dc1-927a-a2d1a5bfa382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch:   5.31208s, FPS=164.154, latency: 0.00459s, 0.00605s, 0.01031s\n",
      "Openvino:  2.45941s, FPS=354.556, latency: 0.00207s, 0.00280s, 0.00367s\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "from statistics import median\n",
    "\n",
    "\n",
    "@torch.no_grad\n",
    "def benchmark(model, dataset):\n",
    "    tokenized_dataset = [{**tokenizer(sample[\"sentence\"], return_tensors=\"pt\")} for sample in dataset]\n",
    "\n",
    "    # warmup\n",
    "    for data in tokenized_dataset[:10]:\n",
    "        model(data)\n",
    "    \n",
    "    times = []\n",
    "    for data in tokenized_dataset:\n",
    "        start = perf_counter()\n",
    "        model(data)\n",
    "        end = perf_counter()\n",
    "        times.append(end - start)\n",
    "\n",
    "    return (\n",
    "        f\"{sum(times):.5f}s, FPS={(len(dataset) / sum(times)):.3f}, \"\n",
    "        f\"latency: {min(times):.5f}s, {median(times):.5f}s, {max(times):.5f}s\"\n",
    "    )\n",
    "\n",
    "print(\"Pytorch:  \", benchmark(lambda x: hf_model(**x), val_dataset))\n",
    "print(\"Openvino: \", benchmark(lambda x: compiled_model(x), val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f9cec1-309b-457d-b388-d4bdf0792762",
   "metadata": {},
   "source": [
    "## Inference Hints (3 балла)\n",
    "\n",
    "Скомпилируйте модель с разными инференс хинтами и сравните результаты бенчмарка. Не забудьте указать \"CPU\" в качестве таргета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a653f8e-6b4a-4727-ad67-7414973aee60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino:  3.34922s, FPS=260.359, latency: 0.00248s, 0.00374s, 0.00744s\n"
     ]
    }
   ],
   "source": [
    "import openvino.properties as props\n",
    "import openvino.properties.hint as hints\n",
    "\n",
    "compiled_througput = ov.compile_model(\n",
    "    ov_model, \n",
    "    \"CPU\", \n",
    "    {hints.performance_mode: hints.PerformanceMode.THROUGHPUT}\n",
    ")\n",
    "print(\"Openvino: \", benchmark(lambda x: compiled_througput(x), val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cee26a4-edb8-47cc-a533-659cba5e4418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino:  2.43760s, FPS=357.728, latency: 0.00203s, 0.00275s, 0.00505s\n"
     ]
    }
   ],
   "source": [
    "compiled_latency = ov.compile_model(\n",
    "    ov_model, \n",
    "    \"CPU\", \n",
    "    {hints.performance_mode: hints.PerformanceMode.LATENCY}\n",
    ")\n",
    "print(\"Openvino: \", benchmark(lambda x: compiled_latency(x), val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9caf3b-059c-45b7-a036-fb29ef3fd1b8",
   "metadata": {},
   "source": [
    "## Async Inference\n",
    "\n",
    "Переписать бенчмарк под асинхронный инференс. Он должен принимать на вход асинхронную очередь и датасет.\n",
    "\n",
    "### Простой Бенчмарк (5 баллов)\n",
    "Простая версия бенчмарка должна замерить FPS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7762d37-ee4f-4e4b-8df5-1974c934e79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino:  0.58401s, FPS=1493.113\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any, Optional\n",
    "\n",
    "\n",
    "def completion_callback(\n",
    "    infer_request: ov.InferRequest, user_data: Optional[Dict[str, Any]] = None\n",
    ") -> None:\n",
    "    ...  # в простом бенчмарке информация из реквеста нам не нужна\n",
    "\n",
    "\n",
    "# benchmark app использует 18 реквестов, очередь без указания jobs создаёт 12\n",
    "infer_queue = ov.AsyncInferQueue(compiled_througput, jobs=18)\n",
    "infer_queue.set_callback(completion_callback)\n",
    "\n",
    "\n",
    "def simple_benchmark_async(queue, dataset):\n",
    "    tokenized_dataset = [{**tokenizer(sample[\"sentence\"], return_tensors=\"np\")} for sample in dataset]\n",
    "\n",
    "    # warmup\n",
    "    for data in tokenized_dataset[:10]:\n",
    "        queue.start_async(data)\n",
    "    queue.wait_all()\n",
    "    \n",
    "    results = [0 for _ in range(len(dataset))]\n",
    "    start = perf_counter()\n",
    "    for idx, data in enumerate(tokenized_dataset):\n",
    "        queue.start_async(data)\n",
    "    queue.wait_all()\n",
    "    end = perf_counter()\n",
    "    elapsed = end - start\n",
    "\n",
    "    return f\"{elapsed:.5f}s, FPS={(len(dataset) / elapsed):.3f}\"\n",
    "\n",
    "\n",
    "print(\"Openvino: \", simple_benchmark_async(infer_queue, val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f675e-f984-4ab1-94dc-6023e3b3cc58",
   "metadata": {},
   "source": [
    "### Добавить Измерение latency В Асинхронный Бенчмарк (14 баллов)\n",
    "\n",
    "Используйте `completion_callback` для подсчёта latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0808d06-8d27-457f-af01-2e62bc8252ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino:  0.55598s, FPS=1568.406, latency: 0.00451s, 0.01018s, 0.03759s\n"
     ]
    }
   ],
   "source": [
    "def completion_callback(\n",
    "    infer_request: ov.InferRequest,\n",
    "    user_data: Dict[str, Any],\n",
    ") -> None:\n",
    "    end = perf_counter()  # инференс завершился, заменяем время\n",
    "    idx = user_data[\"idx\"]\n",
    "    times = user_data[\"times\"]\n",
    "    times[idx] = end - times[idx]  # вычитаем время начала \n",
    "\n",
    "\n",
    "# используем существующую очередь, переназначим коллбэк\n",
    "infer_queue.set_callback(completion_callback)\n",
    "\n",
    "\n",
    "def benchmark_async(queue, dataset):\n",
    "    tokenized_dataset = [{**tokenizer(sample[\"sentence\"], return_tensors=\"np\")} for sample in dataset]\n",
    "    times = [0 for _ in range(len(dataset))]\n",
    "\n",
    "    # warmup\n",
    "    for data in tokenized_dataset[:10]:\n",
    "        queue.start_async(data, {\"idx\": 0, \"times\": times})\n",
    "    queue.wait_all()\n",
    "    \n",
    "    start = perf_counter()\n",
    "    for idx, data in enumerate(tokenized_dataset):\n",
    "        # записываем время старта реквеста в массив по индексу входных данных\n",
    "        times[idx] = perf_counter()\n",
    "        # передаём индекс и массив с началами вместе с входными данными\n",
    "        queue.start_async(data, {\"idx\": idx, \"times\": times})\n",
    "    # ждём пока завершатся все реквесты\n",
    "    queue.wait_all()\n",
    "\n",
    "    # замеряем время конца инференса\n",
    "    end = perf_counter()\n",
    "    # для общего времени исполнения уже нельзя брать sum(times), так как реквесты исполняются одновременно\n",
    "    elapsed = end - start\n",
    "    \n",
    "    return (\n",
    "        f\"{elapsed:.5f}s, FPS={(len(dataset) / elapsed):.3f}, \"\n",
    "        f\"latency: {min(times):.5f}s, {median(times):.5f}s, {max(times):.5f}s\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Openvino: \", benchmark_async(infer_queue, val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea654438-383f-433b-af8b-d8d2e10edba6",
   "metadata": {},
   "source": [
    "`InferRequest` объект сам замеряет latency во время инференса, поэтому можно просто достать время оттуда. Время замеряется в плюсах, поэтому latency получается немного меньше. benchmark app для замеров latency тоже берёт информацию из реквеста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6159109-0330-42fb-b67f-2cd2fed38d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino:  0.54669s, FPS=1595.067, latency: 0.00441s, 0.00960s, 0.03375s\n"
     ]
    }
   ],
   "source": [
    "def latency_from_ir_completion_callback(\n",
    "    infer_request: ov.InferRequest,\n",
    "    user_data: Dict[str, Any],\n",
    ") -> None:\n",
    "    times = user_data[\"times\"]\n",
    "    idx = user_data[\"idx\"]\n",
    "    times[idx] = infer_request.latency * 1e-3  # ms -> s\n",
    "\n",
    "\n",
    "infer_queue.set_callback(latency_from_ir_completion_callback)\n",
    "print(\"Openvino: \", benchmark_async(infer_queue, val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d2dc7-572e-4c17-b7f0-e7efdff8f0bc",
   "metadata": {},
   "source": [
    "## Benchmark App\n",
    "\n",
    "### Измерьте Производительность Модели с Помощью CLI benchmark_app (1 балл)\n",
    "\n",
    "Чтобы не ждать по минуте можете использовать флаг `-t 30`. Выполнение какого слоя занимает больше всего времени?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61c9bc07-8aa6-4109-9b37-fa8e8aee5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            21024 iterations\n",
      "[ INFO ] Duration:         30029.90 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        22.94 ms\n",
      "[ INFO ]    Average:       25.39 ms\n",
      "[ INFO ]    Min:           13.30 ms\n",
      "[ INFO ]    Max:           124.35 ms\n",
      "[ INFO ] Throughput:   700.10 FPS\n"
     ]
    }
   ],
   "source": [
    "!benchmark_app -m \"bert.xml\" -shape [1,128] -t 30 | tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b0092a0-5b06-42b5-aa3c-0571ad6d3aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Statistics report is stored to benchmark_report/benchmark_report.csv\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            21006 iterations\n",
      "[ INFO ] Duration:         30042.05 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        22.96 ms\n",
      "[ INFO ]    Average:       25.36 ms\n",
      "[ INFO ]    Min:           13.39 ms\n",
      "[ INFO ]    Max:           99.35 ms\n",
      "[ INFO ] Throughput:   699.22 FPS\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p benchmark_report\n",
    "!benchmark_app -m \"bert.xml\" -shape [1,128] -t 30 -report_folder benchmark_report -pc -pcsort simple_sort \\\n",
    "-report_type average_counters | tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d78496c4-1449-4211-a4d6-63be5fbea5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layerName,execStatus,layerType,execType,realTime (ms),cpuTime (ms),\"proportion (%)\n",
      "\"\n",
      "__module.bert.encoder.layer.5.intermediate.dense/aten::linear/MatMul,Status.EXECUTED,FullyConnected,brgconv_avx512_1x1_f32,1.108,1.108,4.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 benchmark_report/benchmark_sorted_report.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6bb3fa-1814-4bfe-bb6b-23b508ee8c69",
   "metadata": {},
   "source": [
    "> ⚠️ Окончательный замер всегда нужно проводить с отключенными perf_counter'ами, так как сбор такой статистики замедляет инференс\n",
    "\n",
    "### (Optional) Попробуйте подобрать параметры, чтобы увеличить FPS относительно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9f04ae9-1461-4fa6-a512-8e5eb1e91214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2024.0.0-14509-34caeefd078-releases/2024/0\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] CPU\n",
      "[ INFO ] Build ................................. 2024.0.0-14509-34caeefd078-releases/2024/0\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[ WARNING ] Performance hint was not explicitly specified in command line. Device(CPU) performance hint will be set to PerformanceMode.THROUGHPUT.\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 28.82 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input_ids (node: input_ids) : i64 / [...] / [?,?]\n",
      "[ INFO ]     attention_mask (node: attention_mask) : i64 / [...] / [?,?]\n",
      "[ INFO ]     token_type_ids (node: token_type_ids) : i64 / [...] / [?,?]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     logits (node: __module.classifier/aten::linear/Add) : f32 / [...] / [?,2]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[ INFO ] Reshaping model: 'input_ids': [1,128], 'attention_mask': [1,128], 'token_type_ids': [1,128]\n",
      "[ INFO ] Reshape model took 4.41 ms\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     input_ids (node: input_ids) : i64 / [...] / [1,128]\n",
      "[ INFO ]     attention_mask (node: attention_mask) : i64 / [...] / [1,128]\n",
      "[ INFO ]     token_type_ids (node: token_type_ids) : i64 / [...] / [1,128]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     logits (node: __module.classifier/aten::linear/Add) : f32 / [...] / [1,2]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 279.58 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: Model0\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 24\n",
      "[ INFO ]   NUM_STREAMS: 24\n",
      "[ INFO ]   AFFINITY: Affinity.CORE\n",
      "[ INFO ]   INFERENCE_NUM_THREADS: 24\n",
      "[ INFO ]   PERF_COUNT: NO\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "[ INFO ]   PERFORMANCE_HINT: THROUGHPUT\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   ENABLE_CPU_PINNING: True\n",
      "[ INFO ]   SCHEDULING_CORE_TYPE: SchedulingCoreType.ANY_CORE\n",
      "[ INFO ]   ENABLE_HYPER_THREADING: True\n",
      "[ INFO ]   EXECUTION_DEVICES: ['CPU']\n",
      "[ INFO ]   CPU_DENORMALS_OPTIMIZATION: False\n",
      "[ INFO ]   LOG_LEVEL: Level.NO\n",
      "[ INFO ]   CPU_SPARSE_WEIGHTS_DECOMPRESSION_RATE: 1.0\n",
      "[ INFO ]   DYNAMIC_QUANTIZATION_GROUP_SIZE: 0\n",
      "[ INFO ]   KV_CACHE_PRECISION: <Type: 'float16'>\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'input_ids'!. This input will be filled with random values!\n",
      "[ WARNING ] No input files were given for input 'attention_mask'!. This input will be filled with random values!\n",
      "[ WARNING ] No input files were given for input 'token_type_ids'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'input_ids' with random values \n",
      "[ INFO ] Fill input 'attention_mask' with random values \n",
      "[ INFO ] Fill input 'token_type_ids' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 24 inference requests, limits: 60000 ms duration)\n",
      "[ INFO ] Benchmarking in inference only mode (inputs filling are not included in measurement loop).\n",
      "[ INFO ] First inference took 24.93 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            43776 iterations\n",
      "[ INFO ] Duration:         60036.10 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        30.17 ms\n",
      "[ INFO ]    Average:       32.76 ms\n",
      "[ INFO ]    Min:           21.62 ms\n",
      "[ INFO ]    Max:           88.99 ms\n",
      "[ INFO ] Throughput:   729.16 FPS\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"ov_config.json\", \"w\") as config_file:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"CPU\": {\n",
    "                \"NUM_STREAMS\": 24,\n",
    "                \"INFERENCE_NUM_THREADS\": 48,\n",
    "            }\n",
    "        },\n",
    "        config_file, \n",
    "    )\n",
    "\n",
    "!benchmark_app -m \"bert.xml\" -shape [1,128] -d CPU -load_config ov_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb4e33-062b-4f38-9dea-222e7931378e",
   "metadata": {},
   "source": [
    "За счёт ухудшения latency удалось немного повысить throughput.\n",
    "\n",
    "> ⚠️ Такие измерения нужно производить непосредственно на железе, которое будет использоваться для инференса "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3523e-1299-4881-a66d-ec2febd54a84",
   "metadata": {},
   "source": [
    "## NNCF\n",
    "\n",
    "### Дефолтная Квантизация (5 баллов)\n",
    "\n",
    "Квантизуйте модель с дефолтными параметрами. Замерьте accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82fe28bd-7637-4abc-905e-62bcbe2d4ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b85f0c50ad48a6b528fe0030e61502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc7746fa1624166a8869f7d0640b30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:18 ignored nodes were found by name in the NNCFGraph\n",
      "INFO:nncf:26 ignored nodes were found by name in the NNCFGraph\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503712e0075741a49ce9d15dd00fcae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790328363b9a492b8847be91f60bd1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nncf\n",
    "\n",
    "\n",
    "def transform_fn(text):\n",
    "    return {**tokenizer(text[\"sentence\"], return_tensors=\"np\")}\n",
    "\n",
    "\n",
    "# возьмём для калибрации другой датасет\n",
    "test_dataset = load_dataset(\"glue\", \"sst2\", split=\"test[:300]\")\n",
    "calibration_dataset = nncf.Dataset(test_dataset, transform_fn)\n",
    "quntized_model = nncf.quantize(\n",
    "    ov_model, \n",
    "    calibration_dataset=calibration_dataset,\n",
    "    preset=nncf.QuantizationPreset.MIXED,\n",
    "    target_device=nncf.TargetDevice.CPU,  # важно\n",
    "    model_type=nncf.ModelType.TRANSFORMER,  # очень важно!\n",
    ")\n",
    "ov.save_model(quntized_model, \"qbert.xml\", compress_to_fp16=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4eb14279-03c3-45a9-8898-f8dd8246343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized OpenVINO accuracy: 0.9025229357798165\n"
     ]
    }
   ],
   "source": [
    "compiled_quantized = ov.compile_model(quntized_model, \"CPU\", {hints.performance_mode: hints.PerformanceMode.THROUGHPUT})\n",
    "print(f\"Quantized OpenVINO accuracy: {accuracy_evaluate(compiled_quantized)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390b0ad-89d2-4d1a-bf8e-eaec372ce89c",
   "metadata": {},
   "source": [
    "Замерьте FPS квантизованной модели с помощью benchmark функции или benchmark_app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c20a3484-28b6-41c5-8a1f-815cbc3fd4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino:  0.40821s, FPS=2136.181, latency: 0.00313s, 0.00781s, 0.02472s\n"
     ]
    }
   ],
   "source": [
    "qinfer_queue = ov.AsyncInferQueue(compiled_quantized, jobs=18)\n",
    "qinfer_queue.set_callback(completion_callback)\n",
    "\n",
    "print(\"Openvino: \", benchmark_async(qinfer_queue, val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d0e7741-ff55-49ec-9715-700727e01f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['CPU']\n",
      "[ INFO ] Count:            44334 iterations\n",
      "[ INFO ] Duration:         30023.66 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        10.33 ms\n",
      "[ INFO ]    Average:       11.60 ms\n",
      "[ INFO ]    Min:           6.22 ms\n",
      "[ INFO ]    Max:           60.13 ms\n",
      "[ INFO ] Throughput:   1476.64 FPS\n"
     ]
    }
   ],
   "source": [
    "!benchmark_app -m \"qbert.xml\" -shape [1,128] -t 30 | tail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829e956c-bf5b-43b6-94e5-120dd582609e",
   "metadata": {},
   "source": [
    "### Accuracy Control (10 баллов)\n",
    "\n",
    "Квантизуйте модель так, чтобы потеря accuracy была в пределах 1%. Замерьте FPS получившейся модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad3aaeac-a8ea-4a3c-948a-4be72524c653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed1ad48d7ba4e8d94b2aaf0d2910aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b96613879f48dcba23242fc9626aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Validation of initial model was started\n",
      "INFO:nncf:Elapsed Time: 00:00:00\n",
      "INFO:nncf:Elapsed Time: 00:00:01\n",
      "INFO:nncf:Metric of initial model: 0.8966666666666666\n",
      "INFO:nncf:Collecting values for each data item using the initial model\n",
      "INFO:nncf:Elapsed Time: 00:00:03\n",
      "INFO:nncf:Validation of quantized model was started\n",
      "INFO:nncf:Elapsed Time: 00:00:00\n",
      "INFO:nncf:Elapsed Time: 00:00:01\n",
      "INFO:nncf:Metric of quantized model: 0.85\n",
      "INFO:nncf:Collecting values for each data item using the quantized model\n",
      "INFO:nncf:Elapsed Time: 00:00:04\n",
      "INFO:nncf:Accuracy drop: 0.046666666666666634 (absolute)\n",
      "INFO:nncf:Accuracy drop: 0.046666666666666634 (absolute)\n",
      "INFO:nncf:Total number of quantized operations in the model: 85\n",
      "INFO:nncf:Number of parallel workers to rank quantized operations: 1\n",
      "INFO:nncf:ORIGINAL metric is used to rank quantizers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac743603d05403880328be6bdf8843c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Elapsed Time: 00:03:00\n",
      "INFO:nncf:Changing the scope of quantizer nodes was started\n",
      "INFO:nncf:Reverted 4 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.0.attention.self.key/aten::linear/MatMul\n",
      "\t__module.bert.encoder.layer.0.attention.output/aten::add/Add\n",
      "\t__module.bert.encoder.layer.0.attention.self.value/aten::linear/MatMul\n",
      "\t__module.bert.encoder.layer.0.attention.self.query/aten::linear/MatMul\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.0.output.LayerNorm/aten::layer_norm/MVN\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.023333333333333317 (absolute)\n",
      "INFO:nncf:Re-calculating ranking scores for remaining groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d367e7b674bd48159fedc2fa7b68ff51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Elapsed Time: 00:03:13\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert/aten::rsub/Multiply\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert/aten::rsub/Subtract\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.4.attention.self/aten::matmul/MatMul_1\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.5.attention.self/aten::matmul/MatMul\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.5.attention.self/aten::matmul/MatMul_1\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.5.attention.output.dense/aten::linear/MatMul\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.5.output.dense/aten::linear/MatMul\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.5.output.LayerNorm/aten::layer_norm/MVN\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.pooler.dense/aten::linear/MatMul\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.classifier/aten::linear/MatMul\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.4.attention.output.dense/aten::linear/MatMul\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.019999999999999907 (absolute)\n",
      "INFO:nncf:Re-calculating ranking scores for remaining groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8be7cdaf141465fa8205ee933d8d950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Elapsed Time: 00:02:44\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.5.attention.output.LayerNorm/aten::layer_norm/MVN\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.4.output.LayerNorm/aten::layer_norm/MVN\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 2 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.0.intermediate.dense/aten::linear/MatMul\n",
      "\t__module.bert.encoder.layer.0.output/aten::add/Add\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.016666666666666607 (absolute)\n",
      "INFO:nncf:Reverted 4 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.4.attention.output/aten::add/Add\n",
      "\t__module.bert.encoder.layer.4.attention.self.value/aten::linear/MatMul\n",
      "\t__module.bert.encoder.layer.4.attention.self.key/aten::linear/MatMul\n",
      "\t__module.bert.encoder.layer.4.attention.self.query/aten::linear/MatMul\n",
      "INFO:nncf:Accuracy drop with the new quantization scope is 0.019999999999999907 (absolute)\n",
      "INFO:nncf:Re-calculating ranking scores for remaining groups\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4b21ea2bf24dc9940915c787c3bb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Elapsed Time: 00:02:42\n",
      "INFO:nncf:Reverted 1 operations to the floating-point precision: \n",
      "\t__module.bert.encoder.layer.2.attention.self/aten::matmul/MatMul\n",
      "INFO:nncf:Algorithm completed: achieved required accuracy drop 0.009999999999999898 (absolute)\n",
      "INFO:nncf:19 out of 85 were reverted back to the floating-point precision:\n",
      "\t__module.bert.encoder.layer.0.attention.self.key/aten::linear/MatMul\n",
      "\t__module.bert.encoder.layer.0.attention.output/aten::add/Add\n",
      "\t__module.bert.encoder.layer.0.attention.self.value/aten::linear/MatMul\n",
      "\t__module.bert.encoder.layer.0.attention.self.query/aten::linear/MatMul\n",
      "\t__module.bert/aten::rsub/Multiply\n",
      "\t__module.bert/aten::rsub/Subtract\n",
      "\t__module.bert.encoder.layer.4.attention.self/aten::matmul/MatMul_1\n",
      "\t__module.bert.encoder.layer.5.attention.self/aten::matmul/MatMul\n",
      "\t__module.bert.encoder.layer.5.attention.self/aten::matmul/MatMul_1\n",
      "\t__module.bert.encoder.layer.5.attention.output.dense/aten::linear/MatMul\n",
      "\t__module.bert.encoder.layer.5.output.dense/aten::linear/MatMul\n",
      "\t__module.bert.encoder.layer.5.output.LayerNorm/aten::layer_norm/MVN\n",
      "\t__module.bert.pooler.dense/aten::linear/MatMul\n",
      "\t__module.classifier/aten::linear/MatMul\n",
      "\t__module.bert.encoder.layer.5.attention.output.LayerNorm/aten::layer_norm/MVN\n",
      "\t__module.bert.encoder.layer.4.output.LayerNorm/aten::layer_norm/MVN\n",
      "\t__module.bert.encoder.layer.0.intermediate.dense/aten::linear/MatMul\n",
      "\t__module.bert.encoder.layer.0.output/aten::add/Add\n",
      "\t__module.bert.encoder.layer.2.attention.self/aten::matmul/MatMul\n"
     ]
    }
   ],
   "source": [
    "# разделим валидационный датасет для финальной валидации\n",
    "validation_dataset = list(val_dataset)\n",
    "final_test_dataset, validation_dataset = validation_dataset[:-300], validation_dataset[-300:]\n",
    "validation_dataset = nncf.Dataset(validation_dataset, transform_fn)\n",
    "\n",
    "quntized_model = nncf.quantize_with_accuracy_control(\n",
    "    model=ov_model,\n",
    "    calibration_dataset=calibration_dataset,\n",
    "    preset=nncf.QuantizationPreset.PERFORMANCE,\n",
    "    validation_dataset=validation_dataset,\n",
    "    validation_fn=accuracy_evaluate,  # функция замера accuracy переиспользуется\n",
    "    max_drop=0.01,\n",
    "    target_device=nncf.TargetDevice.CPU,\n",
    "    drop_type=nncf.DropType.ABSOLUTE,\n",
    "    # уберём тип модели, чтобы получить accuracy drop больше 1%\n",
    "    # иначе квантизация будет совпадать с дефолтной 🤷\n",
    "    # model_type=nncf.ModelType.TRANSFORMER, \n",
    ")\n",
    "ov.save_model(quntized_model, \"qbert_acc.xml\", compress_to_fp16=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2781bc92-84ba-464e-9406-59e03ec3f966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openvino: 0.9038461538461539\n",
      "Quantized Openvino :  0.9038461538461539\n",
      "Openvino quantized with acc:  0.8706293706293706\n"
     ]
    }
   ],
   "source": [
    "compiled_quantized_acc = ov.compile_model(\n",
    "    \"qbert_acc.xml\", \"CPU\", {hints.performance_mode: hints.PerformanceMode.THROUGHPUT}\n",
    ")\n",
    "\n",
    "print(f\"Openvino: {accuracy_evaluate(compiled_througput, final_test_dataset)}\")\n",
    "print(f\"Quantized Openvino :  {accuracy_evaluate(compiled_quantized, final_test_dataset)}\")\n",
    "print(f\"Openvino quantized with acc:  {accuracy_evaluate(compiled_quantized_acc, final_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ae888f-f342-419b-8bb4-a9f226920821",
   "metadata": {},
   "source": [
    "Как видно из результатов на тестовом датасете:\n",
    "- Определённый дроп на валидационном датасете ничего не гарантирует.\n",
    "- Указать тип модели бывает важнее, чем дать валидационный датасет.\n",
    "\n",
    "# Дополнительно (2 балла)\n",
    "\n",
    "Добавьте в модель:\n",
    "1. Токенизационный препроцессинг с помощью `openvino-tokenizers`\n",
    "2. (Hard) Добавьте постпроцессинг в модель, чтобы она сразу отдавала результат `np.argmax(logits, axis=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027bb51d-32da-4526-a60c-d06a1f59b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --pre -U openvino-tokenizers --extra-index-url https://storage.openvinotoolkit.org/simple/wheels/nightly git+https://github.com/openvinotoolkit/nncf.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cadc1008-a902-42e3-acbb-58867c1c7e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apaniuko/python/deepschool/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4225: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "RegexNormalization pattern is not supported, operation output might differ from the original tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Model: 'Model1655_with_Model1653'\n",
       "inputs[\n",
       "<ConstOutput: names[Parameter_4126935] shape[?] type: string>\n",
       "]\n",
       "outputs[\n",
       "<ConstOutput: names[logits] shape[?,2] type: f32>\n",
       "]>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openvino_tokenizers import convert_tokenizer, connect_models\n",
    "\n",
    "\n",
    "def get_connected_model(hf_model, tokenizer):\n",
    "    example_input = {**tokenizer(\"test\", return_tensors=\"pt\")}\n",
    "    ov_model = ov.convert_model(hf_model, example_input=example_input)\n",
    "    ov_tokenizer = convert_tokenizer(tokenizer)\n",
    "    return connect_models(ov_tokenizer, ov_model)\n",
    "\n",
    "\n",
    "get_connected_model(hf_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5710e8a7-dd48-4c8a-ab43-1f5ffe12272d",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Требуется добавить кастомную операцию после выхода `logits`. В OpenVINO нет операции `argmax`, но есть [TopK](https://docs.openvino.ai/2024/documentation/openvino-ir-format/operation-sets/operation-specs/sort/top-k-11.html), которая возвращает значения и индексы топ К максимальных элементов - нам нужен второй выход при `k=1`.\n",
    "\n",
    "Воспользуемся [примером](https://docs.openvino.ai/2022.3/openvino_docs_OV_UG_Preprocessing_Details.html#custom-operations) из документации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19d0a178-1d71-4904-bb9e-f46f88953874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RegexNormalization pattern is not supported, operation output might differ from the original tokenizer.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Check 'false' failed at src/core/src/node.cpp:148:\nWhile validating node 'opset11::TopK TopK_4133347 (opset1::Add __module.classifier/aten::linear/Add[0]:f32[?,2], opset1::Constant Constant_4133346[0]:i64[]) -> (f32[?,1], i32[?,1])' with friendly_name 'TopK_4133347':\nDefault output not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m ppp \u001b[38;5;241m=\u001b[39m PrePostProcessor(connected_model)\n\u001b[1;32m     14\u001b[0m ppp\u001b[38;5;241m.\u001b[39moutput(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mpostprocess()\u001b[38;5;241m.\u001b[39mcustom(custom_argmax_1)\n\u001b[0;32m---> 15\u001b[0m connected_model \u001b[38;5;241m=\u001b[39m \u001b[43mppp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/deepschool/venv/lib/python3.10/site-packages/openvino/runtime/utils/decorators.py:89\u001b[0m, in \u001b[0;36mcustom_preprocess_function.<locals>.wrapper\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(custom_function)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(node: Node) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Check 'false' failed at src/core/src/node.cpp:148:\nWhile validating node 'opset11::TopK TopK_4133347 (opset1::Add __module.classifier/aten::linear/Add[0]:f32[?,2], opset1::Constant Constant_4133346[0]:i64[]) -> (f32[?,1], i32[?,1])' with friendly_name 'TopK_4133347':\nDefault output not supported\n"
     ]
    }
   ],
   "source": [
    "from openvino.preprocess import PrePostProcessor\n",
    "from openvino.runtime import opset14 as opset, Output\n",
    "from openvino.runtime.utils.decorators import custom_preprocess_function\n",
    "\n",
    "\n",
    "@custom_preprocess_function\n",
    "def custom_argmax_1(output: Output):\n",
    "    argmax = opset.topk(output, k=1, axis=1, mode=\"max\", sort=\"none\")\n",
    "    return argmax\n",
    "\n",
    "\n",
    "connected_model = get_connected_model(hf_model, tokenizer)\n",
    "ppp = PrePostProcessor(connected_model)\n",
    "ppp.output(\"logits\").postprocess().custom(custom_argmax_1)\n",
    "connected_model = ppp.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be84e800-aa42-408c-b5b5-e0ee096c92e0",
   "metadata": {},
   "source": [
    "Проблема в том, что у PPP есть ограничение - только один вход и один выход. Попробуем вернуть нужный нам выход:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "25431fa5-7943-491b-8712-94d5508a8bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RegexNormalization pattern is not supported, operation output might differ from the original tokenizer.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_from_node(): incompatible function arguments. The following argument types are supported:\n    1. (self: openvino._pyopenvino.Node) -> openvino._pyopenvino.Output\n\nInvoked with: <Output: names[] shape[?,1] type: i32>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m ppp \u001b[38;5;241m=\u001b[39m PrePostProcessor(connected_model)\n\u001b[1;32m      9\u001b[0m ppp\u001b[38;5;241m.\u001b[39moutput(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mpostprocess()\u001b[38;5;241m.\u001b[39mcustom(custom_argmax_2)\n\u001b[0;32m---> 10\u001b[0m connected_model \u001b[38;5;241m=\u001b[39m \u001b[43mppp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/deepschool/venv/lib/python3.10/site-packages/openvino/runtime/utils/decorators.py:89\u001b[0m, in \u001b[0;36mcustom_preprocess_function.<locals>.wrapper\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(custom_function)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(node: Node) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: _from_node(): incompatible function arguments. The following argument types are supported:\n    1. (self: openvino._pyopenvino.Node) -> openvino._pyopenvino.Output\n\nInvoked with: <Output: names[] shape[?,1] type: i32>"
     ]
    }
   ],
   "source": [
    "@custom_preprocess_function\n",
    "def custom_argmax_2(output: Output):\n",
    "    argmax = opset.topk(output, k=1, axis=1, mode=\"max\", sort=\"none\")\n",
    "    return argmax.output(1)\n",
    "\n",
    "\n",
    "connected_model = get_connected_model(hf_model, tokenizer)\n",
    "ppp = PrePostProcessor(connected_model)\n",
    "ppp.output(\"logits\").postprocess().custom(custom_argmax_2)\n",
    "connected_model = ppp.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b85ab-e9bb-422a-9e07-6ff5d52b0785",
   "metadata": {},
   "source": [
    "И тут мимо. Но... стектрейс позволяет нам заглянуть во внутренности `custom_preprocess_function`:\n",
    "```python\n",
    "     87 @wraps(custom_function)\n",
    "     88 def wrapper(node: Node) -> Output:\n",
    "---> 89     return Output._from_node(custom_function(node))\n",
    "```\n",
    "Она берёт ноду (которую мы возвращали в `custom_argmax_1`) и пытается получить её выход. Поэтому мы можем убрать декоратор и вернуть нужный выход самостоятельно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8804a703-282e-4d56-b6c7-4c8d90ab6207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RegexNormalization pattern is not supported, operation output might differ from the original tokenizer.\n",
      "/tmp/tmpctejxcqg/build/third_party/re2/src/extern_re2/re2/re2.cc:205: Error parsing '((?=[^\\n\\t\\r])\\p{Cc})|((?=[^\\n\\t\\r])\\p{Cf})': invalid perl operator: (?=\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{<ConstOutput: names[logits] shape[?,1] type: i32>: array([[0],\n",
       "       [1]], dtype=int32)}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_argmax_3(output: Output):\n",
    "    argmax = opset.topk(output, k=1, axis=1, mode=\"max\", sort=\"none\")\n",
    "    return argmax.output(1)\n",
    "\n",
    "\n",
    "connected_model = get_connected_model(hf_model, tokenizer)\n",
    "ppp = PrePostProcessor(connected_model)\n",
    "ppp.output(\"logits\").postprocess().custom(custom_argmax_3)\n",
    "connected_model_wiht_argmax_1 = ppp.build()\n",
    "\n",
    "compiled_connected = ov.compile_model(connected_model_wiht_argmax_1)\n",
    "compiled_connected([\"Test\", \"Something completely different\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c269041-3b51-4533-ab0a-3df271fa2e1f",
   "metadata": {},
   "source": [
    "Такая кастомная операция оставляет \"лишнюю\" размерность. Её убрать с помощью операции [Squeeze](https://docs.openvino.ai/2024/documentation/openvino-ir-format/operation-sets/operation-specs/shape/squeeze-1.html). У этой операции один выход, поэтому мы можем вернуть `custom_preprocess_function` декоратор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a3bd80df-66d6-46b7-a286-b6d70f7f8454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RegexNormalization pattern is not supported, operation output might differ from the original tokenizer.\n",
      "/tmp/tmpctejxcqg/build/third_party/re2/src/extern_re2/re2/re2.cc:205: Error parsing '((?=[^\\n\\t\\r])\\p{Cc})|((?=[^\\n\\t\\r])\\p{Cf})': invalid perl operator: (?=\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{<ConstOutput: names[class_label] shape[?] type: i32>: array([0, 1], dtype=int32)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@custom_preprocess_function\n",
    "def custom_argmax_4(output: Output):\n",
    "    argmax = opset.topk(output, k=1, axis=1, mode=\"max\", sort=\"none\")\n",
    "    squeeze = opset.squeeze(\n",
    "        data=argmax.output(1),\n",
    "        axes=1,\n",
    "    )\n",
    "    return squeeze\n",
    "\n",
    "connected_model = get_connected_model(hf_model, tokenizer)\n",
    "ppp = PrePostProcessor(connected_model)\n",
    "ppp.output(\"logits\").postprocess().custom(custom_argmax_4)\n",
    "connected_model_wiht_argmax_2 = ppp.build()\n",
    "\n",
    "# поменяем имя выхода\n",
    "connected_model_wiht_argmax_2.output().tensor.set_names({\"class_label\"})\n",
    "\n",
    "compiled_connected = ov.compile_model(connected_model_wiht_argmax_2)\n",
    "compiled_connected([\"Test\", \"Something completely different\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a965bf7-250a-494f-9ec4-90e355da9b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model accuracy: 0.9013761467889908\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad\n",
    "def accuracy_evaluate_for_connected_model(model, dataset=val_dataset, accuracy=accuracy):   \n",
    "    for sample in dataset:\n",
    "        pred = model([sample[\"sentence\"]])[\"class_label\"]\n",
    "        accuracy.add(references=sample[\"label\"], predictions=pred)\n",
    "\n",
    "    return accuracy.compute()[\"accuracy\"]\n",
    "\n",
    "print(f\"Final model accuracy: {accuracy_evaluate_for_connected_model(compiled_connected)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
